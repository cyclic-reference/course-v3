{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from dataclasses import dataclass\n",
    "from functools import reduce, partial\n",
    "import torch\n",
    "from torch import optim\n",
    "from nbs.dl2.exp.nb_02 import getMnistData, assertNearZero\n",
    "from nbs.dl2.exp.nb_03 import Dataset, createDataLoaders, accuracy\n",
    "from nbs.dl2.exp.nb_04 import DataBunch\n",
    "from nbs.dl2.exp.nb_05 import aggregateSchedulers, createCosineSchedulers, cosineScheduler\n",
    "from nbs.dl2.exp.nb_06 import normalizeVectors, createBetterConvolutionModel\n",
    "from nbs.dl2.exp.nb_07D import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "xTraining, yTraining, xValidation, yValidation = getMnistData()\n",
    "xTrainingNormalized, xValidationNormalized = \\\n",
    "    normalizeVectors(xTraining, xValidation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "assertNearZero(xTrainingNormalized.mean())\n",
    "assertNearZero(xValidationNormalized.mean())\n",
    "assertNearZero(1 - xTrainingNormalized.std())\n",
    "assertNearZero(1 - xValidationNormalized.std())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "layerSizes = [8, 16, 32, 64, 64]\n",
    "numberOfClasses = 10\n",
    "hiddenLayerSize = 75\n",
    "batchSize = 64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "trainingDataSet, validationDataSet = Dataset(xTrainingNormalized[:10000], yTraining[:10000]), Dataset(xValidationNormalized[:10000], yValidation[:10000])\n",
    "trainingDataLoader, validationDataLoader = createDataLoaders(trainingDataSet, validationDataSet, batchSize)\n",
    "imageDataBunch = DataBunch(trainingDataLoader, validationDataLoader, numberOfClasses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "phases = [0.3, 0.7]\n",
    "weightsScheduler = aggregateSchedulers(phases, createCosineSchedulers(0.3, 0.6, 0.2)) \n",
    "biasScheduler = aggregateSchedulers(phases, createCosineSchedulers(0.9, 1.8, 0.6))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class ProcessCancellationException(Exception): pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def composeFunctions(funInput, functions): \n",
    "    return reduce(lambda accum, function: function(accum), \n",
    "                  functions, \n",
    "                  funInput)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "result = composeFunctions(0, [\n",
    "    lambda x: x + 1,\n",
    "    lambda x: x + 2,\n",
    "    lambda x: x + 3,\n",
    "])\n",
    "\n",
    "assert result == 6, \"Composition is wrong\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HyperParameters:\n",
    "    learningRate: float"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#export\n",
    "def flatMap(function, items):\n",
    "    return reduce(lambda accum, manyItems: accum + manyItems,\n",
    "           list(map(function, items)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "result = flatMap(lambda n: list(map(lambda _: n+1, range(n+1))), \n",
    "        list(range(3)))\n",
    "\n",
    "assert result == [1, 2, 2, 3, 3, 3], \"Flat map did not work\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "class OptimizationFunction:\n",
    "    \n",
    "    def __call__(self, \n",
    "                 modelLayer, \n",
    "                 hyperParameters: HyperParameters):\n",
    "        return hyperParameters\n",
    "    \n",
    "class LearningRateAnnealer(OptimizationFunction):\n",
    "    def __init__(self, learningRateSupplier)-> None:\n",
    "        self._learningRateSupplier = learningRateSupplier\n",
    "        \n",
    "    def __call__(self, modelLayer, hyperParameters: HyperParameters):\n",
    "        hyperParameters.learningRate = self._learningRateSupplier()\n",
    "        return super().__call__(modelLayer, hyperParameters)\n",
    "    \n",
    "class LearningRateOptimizer(OptimizationFunction):\n",
    "    def __call__(self, \n",
    "                 modelLayer, \n",
    "                 hyperParameters: HyperParameters):\n",
    "        modelLayer.data.add_(-hyperParameters.learningRate, modelLayer.grad.data)\n",
    "        return super().__call__(modelLayer, hyperParameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, modelParameters, \n",
    "                 optimizationFunctions,\n",
    "                 hyperParameters: HyperParameters=HyperParameters(0.5)):\n",
    "        super().__init__()\n",
    "        self._modelParameters = list(modelParameters)\n",
    "        self._hyperParameters = [hyperParameters for _ in self._modelParameters]\n",
    "        self._optimizationFunctions = optimizationFunctions\n",
    "        \n",
    "    def getLayersWithGradients(self):\n",
    "        return list(filter(lambda modelAndHyperParameters: modelAndHyperParameters[0].grad is not None, \n",
    "                           zip(self._modelParameters, self._hyperParameters)))\n",
    "    \n",
    "    def resetGradients(self):\n",
    "        for modelParameter, _ in self.getLayersWithGradients():\n",
    "            modelParameter.grad.detach_()\n",
    "            modelParameter.grad.zero_()\n",
    "    \n",
    "    def optimizeModel(self):\n",
    "        for modelParameter, hyperParameter in self.getLayersWithGradients():\n",
    "            composeFunctions(hyperParameter, \n",
    "                             map(lambda fun: partial(fun, modelParameter), \n",
    "                                 self._optimizationFunctions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "convolutionalModelSR2 = createBetterConvolutionModel(numberOfClasses, layerSizes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 31
    }
   ],
   "source": [
    "optimus = Optimizer(convolutionalModelSR2.parameters(), [])\n",
    "len(optimus.getLayersWithGradients())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "12"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 32
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(convolutionalModelSR2(xTrainingNormalized), yTraining)\n",
    "loss.backward()\n",
    "len(optimus.getLayersWithGradients())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Important Note**: PyTorch will NOT put the gradients on the parameters until backwards has been called on the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "class TrainingSubscriber(StatisticsSubscriber, HookedSubscriber):\n",
    "\n",
    "    def __init__(self,\n",
    "                 lossFunction=torch.nn.functional.cross_entropy,\n",
    "                 schedulingFunction=cosineScheduler(1e-1, 1e-6), \n",
    "                 optimizationFunctions=[]\n",
    "                 ):\n",
    "        super().__init__(name=\"Training\")\n",
    "        self._optimizer: Optimizer = None\n",
    "        self._optimizationFunctions = optimizationFunctions\n",
    "        self._schedulingFunction = schedulingFunction\n",
    "        self._lossFunction = lossFunction\n",
    "\n",
    "    def preModelTeach(self, model, epochs):\n",
    "        super().preModelTeach(model, epochs)\n",
    "        self._optimizer = Optimizer(model.parameters(), \n",
    "                                    [\n",
    "                                        LearningRateAnnealer(lambda: self._schedulingFunction(self._currentEpoch / self._totalEpochs)),\n",
    "                                        LearningRateOptimizer()  \n",
    "                                    ],\n",
    "                                    HyperParameters(\n",
    "                                        learningRate=self._schedulingFunction(0)\n",
    "                                    ))\n",
    "        self._totalEpochs = epochs\n",
    "\n",
    "    def postBatchEvaluation(self, predictions, validationData):\n",
    "        super().postBatchEvaluation(predictions, validationData)\n",
    "        calculatedLoss = self._lossFunction(predictions, validationData)\n",
    "        self._teachModel(calculatedLoss)\n",
    "        self.postBatchLossConsumption(calculatedLoss)\n",
    "\n",
    "    def _teachModel(self, loss):\n",
    "        loss.backward() # adds auto gradients to model parameters\n",
    "        self._optimizer.optimizeModel()\n",
    "        self._optimizer.resetGradients() "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "class TeacherOptimized:\n",
    "    def __init__(self,\n",
    "                 dataBunch,\n",
    "                 trainingSubscriber: TrainingSubscriber,\n",
    "                 validationSubscriber: ValidationSubscriber):\n",
    "        self._dataBunch = dataBunch\n",
    "        self._trainingSubscriber = trainingSubscriber\n",
    "        self._validationSubscriber = validationSubscriber\n",
    "\n",
    "    def teachModel(self, model, numberOfEpochs):\n",
    "        self._notifiyPreTeach(model, numberOfEpochs)\n",
    "        for epoch in range(numberOfEpochs):\n",
    "            self._trainModel(model,\n",
    "                             epoch)\n",
    "            self._validateModel(model,\n",
    "                                epoch)\n",
    "        self._notifiyPostTaught()\n",
    "\n",
    "    def _notifiyPreTeach(self, model, epochs):\n",
    "        self._trainingSubscriber.preModelTeach(model, epochs)\n",
    "        self._validationSubscriber.preModelTeach(model, epochs)\n",
    "\n",
    "    def _notifiyPostTaught(self):\n",
    "        self._trainingSubscriber.postModelTeach()\n",
    "        self._validationSubscriber.postModelTeach()\n",
    "\n",
    "    def _trainModel(self, model, epoch):\n",
    "        self._processData(model,\n",
    "                          self._dataBunch.trainingDataSet,\n",
    "                          epoch,\n",
    "                          self._trainingSubscriber)\n",
    "\n",
    "    def _validateModel(self, model, epoch):\n",
    "        with torch.no_grad():\n",
    "            self._processData(model,\n",
    "                              self._dataBunch.validationDataSet,\n",
    "                              epoch,\n",
    "                              self._validationSubscriber)\n",
    "\n",
    "    def _processData(self,\n",
    "                     model,\n",
    "                     dataLoader,\n",
    "                     epoch,\n",
    "                     processingSubscriber: Subscriber):\n",
    "        processingSubscriber.preEpoch(epoch, dataLoader)\n",
    "        try:\n",
    "            for _xDataBatch, _yDataBatch in dataLoader:\n",
    "                processingSubscriber.preBatchEvaluation()\n",
    "                _predictions = model(_xDataBatch)\n",
    "                processingSubscriber.postBatchEvaluation(_predictions, _yDataBatch)\n",
    "        except ProcessCancellationException: pass\n",
    "        finally:\n",
    "            processingSubscriber.postEpoch(epoch)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "validationSubscriber = ValidationSubscriber()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "trainingSubscriber = TrainingSubscriber()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "teacher = TeacherEnhanced(imageDataBunch, \n",
    "                          trainingSubscriber,\n",
    "                          validationSubscriber\n",
    "                         )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "convolutionalModelSR1 = createBetterConvolutionModel(numberOfClasses, layerSizes)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0961)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 39
    }
   ],
   "source": [
    "accuracy(convolutionalModelSR1(validationDataSet.xVector), validationDataSet.yVector)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch #0 Training: Loss 2.2908337116241455 Accuracy 0.13156847655773163\n",
      "Epoch #0 Validation: Loss 0.0 Accuracy 0.26809731125831604\n",
      "Epoch #1 Training: Loss 1.0839273929595947 Accuracy 0.6810310482978821\n",
      "Epoch #1 Validation: Loss 0.0 Accuracy 0.8797468543052673\n",
      "Epoch #2 Training: Loss 0.34585970640182495 Accuracy 0.8982881903648376\n",
      "Epoch #2 Validation: Loss 0.0 Accuracy 0.9060522317886353\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "teacher.teachModel(convolutionalModelSR1, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "accuracy(convolutionalModelSR1(validationDataSet.xVector), validationDataSet.yVector)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   },
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0990)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 37
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}