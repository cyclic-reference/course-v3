{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from dataclasses import dataclass\n",
    "from functools import reduce\n",
    "import torch\n",
    "from torch import optim\n",
    "from nbs.dl2.exp.nb_02 import getMnistData, assertNearZero\n",
    "from nbs.dl2.exp.nb_03 import Dataset, createDataLoaders, accuracy\n",
    "from nbs.dl2.exp.nb_04 import DataBunch\n",
    "from nbs.dl2.exp.nb_05 import aggregateSchedulers, createCosineSchedulers, cosineScheduler\n",
    "from nbs.dl2.exp.nb_06 import normalizeVectors, createBetterConvolutionModel\n",
    "from nbs.dl2.exp.nb_07D import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "xTraining, yTraining, xValidation, yValidation = getMnistData()\n",
    "xTrainingNormalized, xValidationNormalized = \\\n",
    "    normalizeVectors(xTraining, xValidation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "assertNearZero(xTrainingNormalized.mean())\n",
    "assertNearZero(xValidationNormalized.mean())\n",
    "assertNearZero(1 - xTrainingNormalized.std())\n",
    "assertNearZero(1 - xValidationNormalized.std())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "layerSizes = [8, 16, 32, 64, 64]\n",
    "numberOfClasses = 10\n",
    "hiddenLayerSize = 75\n",
    "batchSize = 64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "trainingDataSet, validationDataSet = Dataset(xTrainingNormalized[:10000], yTraining[:10000]), Dataset(xValidationNormalized[:10000], yValidation[:10000])\n",
    "trainingDataLoader, validationDataLoader = createDataLoaders(trainingDataSet, validationDataSet, batchSize)\n",
    "imageDataBunch = DataBunch(trainingDataLoader, validationDataLoader, numberOfClasses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "phases = [0.3, 0.7]\n",
    "weightsScheduler = aggregateSchedulers(phases, createCosineSchedulers(0.3, 0.6, 0.2)) \n",
    "biasScheduler = aggregateSchedulers(phases, createCosineSchedulers(0.9, 1.8, 0.6))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class ProcessCancellationException(Exception): pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def composeFunctions(funInput, functions): \n",
    "    return reduce(lambda accum, function: function(accum), \n",
    "                  functions, \n",
    "                  funInput)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HyperParameters:\n",
    "    learningRate: float"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def flatMap(function, items):\n",
    "    return reduce(lambda accum, manyItems: accum + manyItems,\n",
    "           list(map(function, items)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 2, 2, 3, 3, 3]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ],
   "source": [
    "flatMap(lambda n: list(map(lambda _: n+1, range(n+1))), \n",
    "        list(range(3)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, modelParameters, \n",
    "                 optimizationFunctions,\n",
    "                 hyperParameters: HyperParameters=HyperParameters(0.5)):\n",
    "        super().__init__()\n",
    "        self._modelParameters = list(modelParameters)\n",
    "        self._hyperParameters = [hyperParameters for _ in self._modelParameters]\n",
    "        self._optimizationFunctions = optimizationFunctions\n",
    "        \n",
    "    def getLayersWithGradients(self):\n",
    "        return list(filter(lambda p: p.grad is not None, self._modelParameters))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "convolutionalModelSR2 = createBetterConvolutionModel(numberOfClasses, layerSizes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "[None, None, None, None, None, None, None, None, None, None, None, None]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 83
    }
   ],
   "source": [
    "optimus = Optimizer(convolutionalModelSR2.parameters(), [])\n",
    "optimus.getLayersWithGradients()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([[[[ 1.6537e-04,  1.5276e-04,  1.2270e-04,  9.5444e-05,  2.9221e-05],\n           [ 2.0994e-04,  1.8922e-04,  1.5616e-04,  1.4520e-04,  1.1184e-04],\n           [ 1.8543e-04,  1.6632e-04,  1.3245e-04,  1.4436e-04,  1.5908e-04],\n           [ 1.3511e-04,  1.3104e-04,  1.1326e-04,  1.4035e-04,  1.7617e-04],\n           [ 1.2411e-04,  1.5057e-04,  1.6889e-04,  2.0645e-04,  2.4725e-04]]],\n \n \n         [[[-3.6407e-04, -3.1179e-04, -2.2377e-04, -1.4259e-04, -1.0727e-04],\n           [-3.9629e-04, -3.3432e-04, -2.4948e-04, -2.0095e-04, -1.8291e-04],\n           [-3.9928e-04, -3.0347e-04, -2.3504e-04, -1.9623e-04, -1.7031e-04],\n           [-3.2954e-04, -2.1940e-04, -1.6649e-04, -1.2502e-04, -9.3775e-05],\n           [-1.8629e-04, -9.1762e-05, -7.7924e-05, -4.9799e-05, -2.7928e-05]]],\n \n \n         [[[-1.0126e-04, -1.2653e-04, -8.3046e-05,  5.5435e-05,  1.9817e-04],\n           [-1.2738e-04, -1.2087e-04, -4.6480e-05,  1.0877e-04,  2.3885e-04],\n           [-1.0219e-04, -6.0637e-05,  3.7349e-05,  1.9386e-04,  2.8918e-04],\n           [-6.9473e-05, -3.2590e-06,  1.1118e-04,  2.5331e-04,  2.9866e-04],\n           [-4.6114e-05,  4.3387e-05,  1.5303e-04,  2.5543e-04,  2.5731e-04]]],\n \n \n         [[[-1.5237e-04, -6.7288e-05, -8.6831e-05, -1.3444e-04, -9.7837e-05],\n           [ 1.0542e-04,  1.1634e-04, -2.5234e-05, -1.5481e-04, -2.0766e-04],\n           [ 3.6357e-04,  2.7943e-04,  7.8179e-05, -4.3446e-05, -1.4441e-04],\n           [ 4.2415e-04,  3.2077e-04,  1.9817e-04,  1.7373e-04,  1.0512e-04],\n           [ 2.4698e-04,  2.2307e-04,  2.7032e-04,  3.5244e-04,  3.2999e-04]]],\n \n \n         [[[ 2.2443e-06,  9.1775e-06, -1.4309e-05, -8.3275e-05, -1.7664e-04],\n           [-1.7426e-04, -1.3800e-04, -1.1833e-04, -1.7382e-04, -2.4540e-04],\n           [-2.3148e-04, -1.8692e-04, -1.2579e-04, -1.8551e-04, -2.7169e-04],\n           [-2.1222e-04, -1.5694e-04, -9.3168e-05, -1.5299e-04, -2.1519e-04],\n           [-2.1951e-04, -1.2464e-04, -3.1138e-05, -5.0159e-05, -6.1310e-05]]],\n \n \n         [[[-1.6121e-05,  1.3224e-05,  1.2057e-05, -2.0343e-05, -1.3217e-04],\n           [ 6.8797e-06,  5.3945e-05,  4.9809e-05,  2.2648e-05, -9.2330e-05],\n           [ 4.3967e-05,  6.8776e-05,  4.3335e-05,  2.2762e-05, -8.5354e-05],\n           [ 5.4681e-05,  5.4299e-05,  1.0961e-05, -2.0919e-05, -1.1361e-04],\n           [ 4.7635e-05,  2.6912e-05, -3.3650e-05, -1.0239e-04, -1.8302e-04]]],\n \n \n         [[[-2.3387e-04, -1.4010e-04, -4.9174e-05, -4.9869e-06,  5.2993e-05],\n           [-2.1446e-04, -1.2344e-04, -4.7500e-05, -6.3561e-06,  2.5580e-05],\n           [-1.8216e-04, -5.5559e-05,  1.6190e-05,  4.0504e-05,  2.4418e-05],\n           [-8.2579e-05,  6.4943e-05,  1.0328e-04,  6.5461e-05,  7.9365e-06],\n           [-1.3391e-05,  1.1335e-04,  1.2235e-04,  8.3494e-05,  1.1212e-05]]],\n \n \n         [[[ 4.4541e-05,  3.9533e-05,  1.4040e-05,  3.5627e-06,  7.2762e-05],\n           [ 2.7266e-06, -5.9389e-06, -5.6641e-05, -9.5717e-05, -5.6146e-05],\n           [ 5.4600e-05,  4.0688e-05, -1.2565e-05, -4.3080e-05, -9.0984e-06],\n           [ 1.5057e-04,  9.1550e-05,  1.9401e-05,  3.2936e-05,  9.4069e-05],\n           [ 1.9344e-04,  9.5198e-05,  2.0607e-05,  7.8464e-05,  1.7894e-04]]]]),\n tensor([-4.9538e-04,  2.1081e-05,  7.6944e-05,  5.2572e-05, -1.2378e-04,\n          9.3499e-05, -2.1036e-04, -5.2615e-05]),\n tensor([[[[-1.5077e-05,  2.2231e-05,  2.5317e-05],\n           [-2.2238e-06,  4.1177e-05,  3.3085e-05],\n           [ 3.6427e-05,  7.6470e-05,  5.4760e-05]],\n \n          [[-1.1822e-05,  4.9875e-05, -3.6857e-05],\n           [ 1.0978e-05,  9.2390e-05,  1.1738e-05],\n           [-2.1418e-04, -1.6909e-04, -1.2729e-04]],\n \n          [[-2.6147e-05,  2.5545e-05,  1.7316e-05],\n           [-1.3926e-05,  5.4238e-05,  1.5250e-05],\n           [-4.1526e-05,  2.7252e-05,  2.7862e-05]],\n \n          ...,\n \n          [[-5.8699e-05,  4.7932e-06, -3.7906e-05],\n           [ 5.3119e-05,  1.0437e-04,  8.9372e-05],\n           [ 1.5099e-04,  1.7746e-04,  1.4313e-04]],\n \n          [[ 1.8421e-04, -9.5466e-05, -1.4201e-04],\n           [ 2.7388e-04,  4.0468e-06, -1.0554e-05],\n           [ 1.9690e-04,  4.0249e-05,  5.4800e-05]],\n \n          [[ 1.0942e-04,  1.1022e-04,  1.0691e-04],\n           [ 5.2587e-05, -2.4175e-05, -4.6981e-05],\n           [ 6.8740e-05,  7.7233e-05,  6.0430e-05]]],\n \n \n         [[[ 1.5882e-06, -3.4161e-05, -8.4300e-06],\n           [-4.0288e-06, -3.0116e-05, -1.5469e-05],\n           [-1.4472e-05, -1.8070e-05, -6.1014e-06]],\n \n          [[ 2.1953e-06,  4.7848e-05, -5.6537e-05],\n           [-1.3108e-05,  2.9385e-06, -5.4098e-05],\n           [ 6.2408e-05,  2.3082e-05, -1.0986e-04]],\n \n          [[ 2.3554e-05,  1.1325e-05, -1.6054e-05],\n           [-6.0672e-07, -1.0376e-05, -2.6274e-05],\n           [-2.6707e-06, -1.8575e-05, -4.4267e-05]],\n \n          ...,\n \n          [[-2.1636e-05, -5.7759e-05, -2.0536e-05],\n           [-6.3750e-05, -3.6723e-05, -5.3691e-06],\n           [-8.7403e-05, -5.5486e-05,  8.1455e-06]],\n \n          [[-4.1118e-05, -2.8095e-07,  5.9339e-05],\n           [-5.5342e-05, -3.4748e-05,  5.0653e-05],\n           [-7.4817e-06, -1.3531e-05,  4.7628e-05]],\n \n          [[ 1.1618e-04,  1.0386e-04,  1.1593e-05],\n           [ 6.3748e-05,  4.6823e-06, -4.3249e-05],\n           [-1.4141e-05, -3.0545e-05, -5.7660e-05]]],\n \n \n         [[[ 1.1063e-04,  1.0496e-04,  1.0183e-04],\n           [ 1.3095e-04,  1.4393e-04,  1.4392e-04],\n           [ 1.3504e-04,  1.4650e-04,  1.6309e-04]],\n \n          [[-9.5235e-05,  6.8844e-05,  2.1806e-04],\n           [-1.1228e-05,  1.7941e-05,  1.0142e-04],\n           [ 4.2552e-05,  2.0291e-05,  5.0199e-05]],\n \n          [[ 7.6191e-05,  1.3492e-04,  1.8183e-04],\n           [ 1.2188e-04,  1.5486e-04,  1.7197e-04],\n           [ 1.6296e-04,  1.2561e-04,  1.2822e-04]],\n \n          ...,\n \n          [[ 4.7124e-05,  9.4869e-05,  1.0507e-04],\n           [ 1.1598e-04,  1.4570e-04,  9.1022e-05],\n           [ 1.0401e-04,  1.1119e-04,  7.2725e-05]],\n \n          [[ 2.2468e-04,  1.5730e-04, -4.0030e-05],\n           [ 2.0001e-04,  4.4830e-05, -1.4356e-04],\n           [ 1.4222e-04, -5.6636e-05, -1.2485e-04]],\n \n          [[ 1.8957e-04,  1.8144e-04,  6.5957e-05],\n           [ 1.4194e-04,  4.8519e-05,  1.8826e-05],\n           [ 1.5450e-05, -5.1072e-05, -5.1614e-05]]],\n \n \n         ...,\n \n \n         [[[ 1.1707e-04,  1.0656e-04,  1.1441e-04],\n           [ 8.6494e-05,  7.1585e-05,  7.2015e-05],\n           [ 7.2746e-05,  9.0949e-05,  8.5845e-05]],\n \n          [[ 3.4695e-05,  3.3464e-05, -2.0510e-04],\n           [ 2.2645e-05, -1.5285e-05, -4.9431e-04],\n           [ 9.6322e-05, -1.1994e-04, -3.3217e-04]],\n \n          [[ 1.0627e-04,  8.1841e-05,  8.7637e-06],\n           [ 8.9966e-05,  6.9018e-05, -1.0464e-04],\n           [ 8.4676e-05,  2.2702e-05, -9.7684e-05]],\n \n          ...,\n \n          [[ 1.7302e-04,  1.1003e-04,  8.0656e-05],\n           [ 1.2686e-04,  6.5418e-05,  7.5949e-05],\n           [ 4.0697e-05,  7.3529e-05,  1.1327e-04]],\n \n          [[-2.4088e-05, -1.8725e-04,  1.3460e-05],\n           [-3.5281e-05, -7.8197e-05,  9.8186e-05],\n           [ 1.2955e-05,  8.8132e-06,  1.3218e-04]],\n \n          [[-3.2081e-05, -1.2813e-04, -1.4888e-04],\n           [-8.8296e-05, -1.4760e-04,  2.0800e-06],\n           [-1.9007e-05, -9.1436e-05,  9.6379e-05]]],\n \n \n         [[[ 5.8650e-05,  5.2920e-05,  4.1758e-05],\n           [ 5.1933e-05,  4.9439e-05,  3.6839e-05],\n           [ 4.6673e-05,  3.0086e-05,  2.4241e-05]],\n \n          [[-2.0264e-04, -2.2152e-05,  7.7866e-05],\n           [-4.9927e-05, -2.9341e-05,  9.3486e-05],\n           [ 1.5043e-05,  4.0858e-05,  1.5205e-04]],\n \n          [[-1.0894e-05,  4.9300e-05,  6.7272e-05],\n           [ 3.0048e-05,  3.8171e-05,  8.0662e-05],\n           [ 3.2976e-05,  3.4977e-05,  9.0076e-05]],\n \n          ...,\n \n          [[ 7.7428e-05,  7.1624e-05,  5.9498e-05],\n           [ 9.1966e-05,  7.9873e-05,  2.5433e-05],\n           [ 8.0396e-05,  6.3512e-05,  2.0827e-05]],\n \n          [[ 1.0613e-04,  6.0772e-05, -3.5572e-05],\n           [ 6.8542e-05, -7.6857e-06, -6.5128e-05],\n           [ 3.7282e-05,  2.9890e-06, -3.1130e-05]],\n \n          [[ 5.7911e-05,  6.2047e-05,  3.6695e-06],\n           [ 1.8729e-06, -2.4508e-06, -3.0766e-05],\n           [-4.3123e-05, -3.4858e-05, -4.9953e-05]]],\n \n \n         [[[ 1.2280e-04,  1.5197e-04,  1.6018e-04],\n           [ 1.4273e-04,  1.7381e-04,  1.5273e-04],\n           [ 1.4671e-04,  1.7934e-04,  1.7768e-04]],\n \n          [[ 1.6929e-05, -3.3316e-04, -1.7764e-05],\n           [-6.5074e-05, -2.4302e-04,  1.9369e-04],\n           [ 3.0096e-05, -1.3985e-04,  6.3708e-05]],\n \n          [[ 1.3964e-04,  7.4176e-06,  1.1701e-04],\n           [ 1.3107e-04,  4.8807e-05,  2.3907e-04],\n           [ 1.6301e-04,  7.1952e-05,  1.4977e-04]],\n \n          ...,\n \n          [[ 4.9554e-05,  1.3159e-04,  1.2442e-04],\n           [ 8.0745e-05,  1.7135e-04,  1.5795e-04],\n           [ 6.1704e-05,  1.6528e-04,  1.5840e-04]],\n \n          [[ 1.5508e-04,  2.0948e-04,  5.8705e-05],\n           [ 1.8822e-04,  1.6838e-04,  3.9803e-05],\n           [ 1.3892e-04,  1.1361e-04,  4.1146e-05]],\n \n          [[-1.0865e-05,  7.8668e-05,  2.1076e-04],\n           [ 1.1520e-04,  1.0557e-04,  1.1590e-04],\n           [ 8.2747e-05,  2.9946e-06,  1.0534e-04]]]]),\n tensor([-8.0556e-05,  6.1752e-05, -3.6326e-04,  1.4809e-04, -1.1345e-04,\n          5.5316e-04,  3.8154e-04, -3.0627e-04,  2.0310e-04,  4.0401e-04,\n          1.6761e-04,  4.2593e-04,  2.3575e-04, -1.3309e-04, -7.7343e-05,\n         -4.2346e-04]),\n tensor([[[[-1.2280e-04, -1.2784e-05,  7.3804e-05],\n           [-5.1303e-05,  6.2749e-05, -4.2706e-05],\n           [ 1.4043e-05, -9.9763e-05, -9.3915e-05]],\n \n          [[-5.3710e-05,  2.1197e-05, -1.6779e-05],\n           [-7.3323e-05, -9.4024e-05, -3.6750e-05],\n           [-1.1036e-04, -1.5796e-04, -3.4088e-05]],\n \n          [[-1.3035e-04, -1.2998e-04, -4.4619e-05],\n           [-1.0905e-04, -1.2095e-04, -5.4477e-05],\n           [-9.5380e-05, -8.5552e-05, -4.6345e-05]],\n \n          ...,\n \n          [[-7.3054e-05,  8.4743e-05,  3.5200e-05],\n           [-1.2730e-05,  3.7882e-05, -3.7697e-06],\n           [ 5.9166e-06, -1.5139e-04, -2.5248e-06]],\n \n          [[-1.4395e-04, -1.4825e-04, -7.1466e-05],\n           [-1.1760e-04, -1.2919e-04, -8.9827e-05],\n           [-9.2453e-05, -1.2170e-04, -4.0729e-05]],\n \n          [[-1.0992e-04, -2.1131e-04,  1.2659e-05],\n           [-1.3392e-04, -8.9021e-05, -3.2631e-05],\n           [ 1.0938e-05, -6.4067e-05, -1.7130e-04]]],\n \n \n         [[[ 9.3962e-05,  2.9402e-04,  1.0334e-04],\n           [ 2.0087e-04,  8.2342e-05, -3.6096e-05],\n           [ 1.2804e-04, -7.8276e-06,  3.5607e-05]],\n \n          [[ 2.1669e-04,  2.2346e-04,  7.2233e-05],\n           [ 1.6865e-04,  7.7595e-05, -1.1270e-04],\n           [ 9.9232e-05,  5.6389e-05,  3.1251e-06]],\n \n          [[ 1.5233e-04,  5.1150e-06,  5.8260e-05],\n           [ 1.2100e-04, -3.5770e-05, -1.6800e-05],\n           [ 3.4765e-05,  8.2927e-05,  5.7154e-05]],\n \n          ...,\n \n          [[ 6.8425e-05,  3.7691e-04,  4.1012e-05],\n           [ 2.3310e-04,  1.1210e-04, -1.2029e-04],\n           [ 7.7012e-05, -1.5612e-05, -1.9223e-05]],\n \n          [[ 9.6259e-05,  4.5361e-05, -1.7946e-05],\n           [ 5.6379e-05,  1.8027e-05,  4.5860e-05],\n           [ 5.6308e-05,  1.0650e-04,  1.4856e-04]],\n \n          [[ 6.7600e-05,  5.1613e-05,  7.0233e-05],\n           [ 1.0644e-04,  1.2102e-04,  7.9388e-05],\n           [ 8.4878e-05,  9.7748e-05,  1.2169e-04]]],\n \n \n         [[[ 5.8902e-05,  5.3093e-05,  6.7493e-06],\n           [-1.1105e-04, -2.5237e-04,  3.2090e-06],\n           [-2.0647e-04,  1.0555e-04, -5.6292e-05]],\n \n          [[-1.2637e-04, -3.0383e-06, -1.5355e-06],\n           [-7.6235e-05,  7.9652e-05, -9.8825e-05],\n           [ 5.2059e-05,  9.3974e-05, -1.8440e-04]],\n \n          [[ 1.2177e-05,  3.3096e-05,  2.0955e-05],\n           [-8.1691e-05, -1.4540e-05, -2.2224e-05],\n           [-5.8844e-05, -3.7960e-05,  5.2327e-05]],\n \n          ...,\n \n          [[-5.6471e-05, -5.2777e-05, -3.8550e-05],\n           [-9.1828e-05, -8.6424e-05, -6.0873e-05],\n           [-8.9923e-05,  2.2418e-04, -1.5714e-04]],\n \n          [[-1.7366e-05,  2.9436e-05,  6.2069e-05],\n           [-6.4477e-05,  7.3184e-05,  9.1282e-05],\n           [-7.8368e-05, -1.9578e-05, -1.7166e-05]],\n \n          [[ 2.4458e-04,  1.8532e-04,  2.8323e-05],\n           [-2.6055e-05, -7.1717e-05,  6.5832e-05],\n           [-5.4988e-05, -9.8882e-05,  1.8081e-04]]],\n \n \n         ...,\n \n \n         [[[-2.4223e-04, -8.8624e-05,  3.7356e-05],\n           [-1.0633e-04, -1.1934e-04, -3.3834e-04],\n           [-1.7056e-05, -1.6756e-04, -3.0500e-05]],\n \n          [[-8.5926e-05, -6.4529e-05, -2.0250e-04],\n           [-1.1952e-04, -1.4616e-04, -1.7360e-04],\n           [-1.1908e-04, -1.0843e-04,  5.5956e-05]],\n \n          [[-2.2178e-04, -2.4676e-04, -2.4015e-04],\n           [-1.0467e-04, -3.0537e-04,  3.3966e-05],\n           [-1.6170e-04, -1.4156e-04, -9.7698e-05]],\n \n          ...,\n \n          [[-2.0369e-05,  1.8798e-04,  2.5176e-04],\n           [-4.7954e-05, -1.9348e-04, -2.7535e-04],\n           [ 2.4006e-04, -4.9969e-05,  5.8423e-05]],\n \n          [[-2.3995e-04, -2.8570e-04, -2.5401e-04],\n           [-2.6870e-04, -2.6813e-04, -1.3254e-04],\n           [-2.3646e-04, -2.3189e-04, -7.6595e-05]],\n \n          [[-3.7210e-04, -3.4051e-04, -2.9369e-04],\n           [-2.7944e-04, -4.2000e-05, -1.8483e-04],\n           [-2.8765e-04, -1.0179e-04, -3.6786e-05]]],\n \n \n         [[[-9.9703e-05, -2.2454e-05, -9.0356e-05],\n           [-8.4527e-05, -3.2147e-05,  1.0516e-06],\n           [ 3.8538e-05,  1.5916e-04, -1.2938e-05]],\n \n          [[-7.6987e-05, -3.0468e-05, -6.9757e-05],\n           [-3.6631e-05,  4.9405e-05, -4.8131e-05],\n           [ 7.2124e-05,  1.2421e-04, -3.2336e-05]],\n \n          [[-7.4882e-05, -3.1456e-05,  1.3475e-05],\n           [-1.1302e-04, -1.0527e-05, -1.8146e-06],\n           [ 2.1637e-05,  1.0395e-04,  5.7929e-05]],\n \n          ...,\n \n          [[-6.4192e-05, -5.0623e-06, -7.3665e-05],\n           [-4.9317e-05,  7.9975e-05,  1.2856e-06],\n           [ 2.0461e-05,  1.0968e-04, -5.9867e-05]],\n \n          [[-1.1621e-04, -1.5768e-05,  2.2263e-05],\n           [-7.8548e-05,  1.1843e-06,  5.1675e-05],\n           [ 4.3873e-05,  1.2722e-04,  4.9009e-05]],\n \n          [[-7.3323e-05,  2.9143e-05,  3.1041e-05],\n           [-6.2100e-05, -3.5410e-05,  6.5807e-05],\n           [ 5.2131e-05,  1.1197e-04,  1.4296e-04]]],\n \n \n         [[[-3.8789e-05, -5.7810e-06, -1.0975e-05],\n           [-1.2945e-05, -1.0173e-05, -4.9053e-05],\n           [ 3.5035e-05, -3.2164e-06, -1.7373e-05]],\n \n          [[ 4.0367e-06,  7.3792e-06, -2.8983e-05],\n           [ 3.5358e-05,  8.2252e-06, -4.3215e-05],\n           [ 3.6194e-05, -5.4544e-06, -2.6751e-05]],\n \n          [[ 2.4715e-05, -8.1082e-06, -2.5743e-05],\n           [-1.7477e-05, -1.5664e-05, -2.0012e-05],\n           [-1.8743e-05,  1.3076e-05, -3.9568e-05]],\n \n          ...,\n \n          [[-2.3041e-05, -1.1950e-05,  4.3197e-07],\n           [ 1.9365e-05, -1.9723e-05, -4.4385e-05],\n           [ 2.4590e-05, -2.2812e-05,  9.2689e-06]],\n \n          [[ 2.0707e-05,  2.9821e-05, -1.5990e-05],\n           [-2.0453e-05, -2.0558e-05, -4.0768e-05],\n           [ 1.2104e-05, -8.7368e-06, -4.6331e-05]],\n \n          [[ 8.7476e-06,  4.5602e-05, -1.9811e-05],\n           [-3.0643e-05,  2.0893e-05, -4.9284e-05],\n           [-6.1026e-06,  2.7923e-05, -1.1685e-05]]]]),\n tensor([ 2.9457e-04, -1.2451e-04, -2.1601e-05,  3.1724e-04, -3.4017e-04,\n          3.2886e-04, -1.5782e-04,  6.6136e-05,  7.1723e-04, -8.1976e-04,\n         -1.0235e-03,  4.9204e-04,  1.7139e-05,  1.1714e-05, -2.7368e-04,\n         -9.0707e-04, -5.5070e-05, -3.5940e-04, -7.4848e-06, -1.0702e-04,\n          8.6383e-05,  2.9294e-04, -4.6398e-04, -6.2054e-05, -1.3736e-04,\n          2.9763e-04,  2.1474e-05, -7.4448e-04, -3.4570e-04,  6.8519e-04,\n          8.0521e-06,  2.1950e-05]),\n tensor([[[[-2.1244e-05, -1.2793e-04, -1.0273e-05],\n           [-2.8398e-06, -1.2609e-04, -4.9251e-05],\n           [ 6.0558e-07, -1.4469e-04, -1.2726e-04]],\n \n          [[ 8.8480e-06, -1.3254e-04, -1.4164e-04],\n           [-3.2265e-05, -1.3749e-04, -1.4162e-04],\n           [ 2.8075e-06, -1.0620e-04, -7.9758e-05]],\n \n          [[ 6.3169e-05, -1.5187e-04, -2.7431e-04],\n           [ 6.6683e-06, -7.4771e-05, -1.8054e-04],\n           [-6.2287e-06, -1.6415e-04, -2.6446e-04]],\n \n          ...,\n \n          [[-3.1189e-05, -3.5072e-05,  2.4232e-05],\n           [-6.5171e-06, -5.3416e-05, -1.1971e-04],\n           [ 1.2154e-05, -4.9826e-05, -8.0059e-05]],\n \n          [[ 1.0410e-05, -1.2556e-04, -1.7283e-04],\n           [ 7.3448e-06, -7.7877e-05, -1.2082e-04],\n           [-2.6077e-06, -1.3856e-04, -1.3910e-04]],\n \n          [[ 8.0066e-06, -1.4574e-04, -1.3792e-04],\n           [-1.9147e-07, -1.3388e-04, -1.5684e-04],\n           [ 1.1403e-06, -1.3220e-04, -1.3246e-04]]],\n \n \n         [[[-8.9011e-06,  1.0825e-04,  9.5921e-05],\n           [-9.4613e-06,  5.9233e-05,  8.7562e-05],\n           [ 8.6351e-05,  7.0141e-06,  7.4082e-05]],\n \n          [[ 3.9820e-05,  9.9726e-06,  9.3347e-05],\n           [-6.4143e-05,  1.4006e-04,  6.4855e-05],\n           [ 1.2599e-05,  2.3799e-06,  9.7203e-05]],\n \n          [[ 1.6850e-04,  1.1086e-04,  9.5789e-05],\n           [-6.3291e-05,  2.0785e-05,  5.8633e-05],\n           [ 7.4405e-06, -1.1904e-05,  2.8046e-05]],\n \n          ...,\n \n          [[ 6.3731e-05,  2.9930e-04,  4.0969e-05],\n           [ 1.8407e-04,  3.9139e-04,  1.0996e-04],\n           [ 1.3514e-04,  1.1402e-04,  2.1383e-05]],\n \n          [[ 1.0078e-04,  1.4172e-04,  9.6615e-06],\n           [ 9.3563e-05,  1.4365e-04,  6.5508e-05],\n           [ 7.5313e-05,  8.0063e-05,  5.8925e-05]],\n \n          [[ 7.0633e-05,  6.3205e-05,  8.9802e-05],\n           [ 9.3758e-05,  8.5417e-05,  6.7456e-05],\n           [ 8.8835e-05,  8.0559e-05,  8.2005e-05]]],\n \n \n         [[[-1.8485e-04, -5.0325e-04, -4.3929e-04],\n           [-4.4884e-04, -6.5540e-04, -6.2835e-04],\n           [-3.4165e-04, -6.5220e-04, -6.5712e-04]],\n \n          [[-2.5470e-04, -4.4683e-04, -4.3079e-04],\n           [-3.5983e-04, -7.4536e-04, -6.6635e-04],\n           [-4.1439e-04, -4.3935e-04, -5.8725e-04]],\n \n          [[-2.1783e-04, -3.4030e-04, -3.8702e-04],\n           [-3.6225e-04, -4.7838e-04, -6.3974e-04],\n           [-3.9400e-04, -6.5225e-04, -6.0989e-04]],\n \n          ...,\n \n          [[-1.7450e-04, -1.6747e-04, -1.7812e-04],\n           [-4.5981e-04, -5.7234e-04, -4.4615e-04],\n           [-1.7055e-04, -5.1057e-04, -4.9163e-04]],\n \n          [[-2.7814e-04, -3.9311e-04, -4.0154e-04],\n           [-4.9911e-04, -6.3895e-04, -6.1473e-04],\n           [-5.2776e-04, -7.1350e-04, -6.3394e-04]],\n \n          [[-2.5703e-04, -4.5176e-04, -4.3201e-04],\n           [-5.0123e-04, -6.6740e-04, -6.2924e-04],\n           [-4.9129e-04, -6.0373e-04, -6.1362e-04]]],\n \n \n         ...,\n \n \n         [[[-2.3672e-04, -1.3668e-05, -2.1390e-04],\n           [-9.7329e-05, -1.4083e-04, -1.4644e-04],\n           [-1.0860e-04, -1.5208e-04, -1.6813e-04]],\n \n          [[-8.8613e-05, -1.5505e-04, -1.2974e-04],\n           [-1.9853e-04, -1.0692e-04, -3.5917e-04],\n           [-4.4734e-05, -1.6253e-04, -1.2095e-04]],\n \n          [[ 1.1034e-04,  5.3814e-05,  3.8831e-06],\n           [-1.0095e-04, -1.7135e-04, -4.5079e-04],\n           [-1.4782e-04, -1.8524e-05, -3.8525e-04]],\n \n          ...,\n \n          [[-2.3833e-04, -1.9970e-04, -1.6038e-04],\n           [ 8.6881e-06, -1.0260e-04, -9.8485e-06],\n           [-1.7583e-04, -1.9937e-04, -1.9748e-04]],\n \n          [[-9.5684e-05, -4.1138e-05, -3.5303e-05],\n           [-1.4527e-04, -2.3869e-04, -1.3886e-04],\n           [-1.4312e-04, -1.7281e-04, -1.7214e-04]],\n \n          [[-1.3115e-04, -1.1667e-04, -1.2260e-04],\n           [-1.3795e-04, -1.6622e-04, -1.4571e-04],\n           [-1.3352e-04, -1.8146e-04, -1.6916e-04]]],\n \n \n         [[[-1.0603e-05,  3.4363e-05,  3.5740e-05],\n           [ 7.9185e-06, -1.7753e-04, -1.9081e-04],\n           [ 1.6808e-05, -1.6927e-04, -1.5990e-04]],\n \n          [[-3.8365e-06,  1.3452e-05,  2.5480e-05],\n           [ 2.8555e-05, -1.6360e-04, -1.3974e-04],\n           [ 1.3962e-05, -1.9672e-04, -1.5122e-04]],\n \n          [[ 2.5843e-05,  2.4251e-05,  8.6607e-06],\n           [ 8.2330e-06, -1.4563e-04, -1.2883e-04],\n           [ 5.2393e-05, -8.6584e-05, -5.2234e-05]],\n \n          ...,\n \n          [[-3.1910e-05, -7.4989e-06,  1.0598e-05],\n           [ 1.0149e-05, -1.2704e-04, -1.7652e-04],\n           [-6.1759e-05, -7.2079e-05, -6.1118e-05]],\n \n          [[ 1.5953e-06,  1.3475e-05,  3.5085e-05],\n           [-1.2047e-05, -1.1414e-04, -1.7027e-04],\n           [ 2.5990e-06, -1.2278e-04, -1.8254e-04]],\n \n          [[-3.2525e-06,  2.3678e-05,  2.4751e-05],\n           [ 4.1433e-06, -1.7387e-04, -1.7914e-04],\n           [-2.6054e-06, -1.8396e-04, -1.7249e-04]]],\n \n \n         [[[ 1.0688e-05, -2.9842e-05, -2.6773e-05],\n           [ 2.7104e-05, -3.0719e-05, -2.7734e-05],\n           [ 2.7795e-05, -2.1610e-05, -3.9512e-05]],\n \n          [[ 6.9744e-06, -3.3298e-05, -3.0178e-05],\n           [ 4.5328e-05, -5.6088e-05, -4.5557e-05],\n           [ 3.9505e-05, -4.8678e-05, -2.5455e-05]],\n \n          [[ 3.1540e-05, -1.2844e-05, -1.2185e-05],\n           [ 4.2881e-05, -1.8198e-05, -3.4727e-05],\n           [ 6.1742e-05, -1.3359e-05, -2.8190e-05]],\n \n          ...,\n \n          [[-1.6644e-05, -1.5781e-05, -1.5203e-05],\n           [ 6.0383e-06, -2.9038e-05, -5.8106e-05],\n           [-3.6696e-05, -5.7643e-05, -2.1087e-05]],\n \n          [[ 1.2486e-05, -1.9035e-05, -3.0790e-05],\n           [ 1.9135e-05, -3.3414e-05, -3.0365e-05],\n           [ 2.3814e-05, -3.7968e-05, -2.2974e-05]],\n \n          [[ 9.8838e-06, -3.4054e-05, -3.3193e-05],\n           [ 2.8395e-05, -4.3231e-05, -4.2342e-05],\n           [ 2.5786e-05, -4.0394e-05, -4.4934e-05]]]]),\n tensor([ 3.2249e-04, -1.9059e-04,  1.5649e-03, -2.8191e-04, -9.1089e-06,\n         -4.3816e-04,  1.0788e-04, -1.7693e-04, -8.2797e-04,  1.8290e-04,\n          2.2648e-04,  8.9041e-04, -5.5629e-04,  5.6670e-04, -1.6352e-03,\n         -3.2653e-04,  6.7110e-04,  5.2245e-04,  1.0394e-03, -6.6996e-04,\n         -1.1126e-04, -5.1058e-04, -6.1396e-04, -1.8646e-04, -4.0475e-04,\n         -8.1538e-06, -1.1032e-04,  1.3212e-03, -3.1725e-05,  1.6176e-04,\n         -3.9239e-05, -2.4424e-04, -5.8340e-04, -5.5791e-04, -6.0690e-04,\n         -7.2857e-05, -8.2379e-06, -1.6223e-03,  1.2139e-03, -7.5568e-04,\n          4.1843e-04,  1.3676e-04,  2.0266e-04,  1.9545e-04, -1.4591e-05,\n          6.6015e-05,  4.6939e-04,  4.1415e-06,  1.8989e-04, -7.8863e-04,\n          8.4381e-05,  5.0763e-04,  7.1598e-04, -2.0395e-03,  7.2888e-04,\n         -2.6712e-04,  8.5798e-04,  1.3713e-03,  1.3214e-03, -6.2529e-05,\n          9.6278e-04,  4.1689e-04,  4.2878e-04,  9.7646e-05]),\n tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -1.2264e-03, -1.2643e-03],\n           [ 0.0000e+00, -6.9995e-04, -1.1716e-03]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -1.2504e-03, -1.2407e-03],\n           [ 0.0000e+00, -1.2087e-03, -1.0168e-03]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -1.1358e-03, -9.4651e-04],\n           [ 0.0000e+00, -1.2312e-03, -5.6308e-04]],\n \n          ...,\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -1.2070e-03, -1.2656e-03],\n           [ 0.0000e+00, -4.7747e-04, -1.5716e-03]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -1.1073e-03, -1.1777e-03],\n           [ 0.0000e+00, -1.1720e-03, -1.2307e-03]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -1.1846e-03, -1.1317e-03],\n           [ 0.0000e+00, -1.1596e-03, -1.1336e-03]]],\n \n \n         [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -6.4354e-04, -6.0403e-04],\n           [ 0.0000e+00, -1.7372e-04, -5.4056e-04]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -6.4942e-04, -6.1508e-04],\n           [ 0.0000e+00, -6.8231e-04, -5.3458e-04]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -6.1603e-04, -1.5465e-04],\n           [ 0.0000e+00, -6.5805e-04, -5.8982e-04]],\n \n          ...,\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -5.4345e-04, -6.3145e-04],\n           [ 0.0000e+00, -4.8907e-04, -5.4974e-04]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -5.9811e-04, -5.8913e-04],\n           [ 0.0000e+00, -6.0843e-04, -6.7655e-04]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -6.5672e-04, -5.7837e-04],\n           [ 0.0000e+00, -6.6089e-04, -5.3585e-04]]],\n \n \n         [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00,  9.6882e-04,  9.9727e-04],\n           [ 0.0000e+00,  9.4747e-04,  1.0318e-03]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00,  9.9729e-04,  9.6763e-04],\n           [ 0.0000e+00,  9.1275e-04,  6.3663e-04]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00,  9.3808e-04,  1.0079e-03],\n           [ 0.0000e+00,  8.8651e-04,  1.1765e-03]],\n \n          ...,\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00,  9.5552e-04,  9.7143e-04],\n           [ 0.0000e+00,  4.4479e-04,  9.6751e-04]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00,  1.0335e-03,  9.3262e-04],\n           [ 0.0000e+00,  1.0014e-03,  9.9024e-04]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00,  9.4690e-04,  9.9261e-04],\n           [ 0.0000e+00,  9.1610e-04,  1.0035e-03]]],\n \n \n         ...,\n \n \n         [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -6.6818e-06, -2.0660e-05],\n           [ 0.0000e+00,  7.7470e-05, -1.4047e-05]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00,  9.4678e-07, -2.2979e-05],\n           [ 0.0000e+00,  2.7954e-05, -5.3357e-05]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00,  2.8322e-05, -1.4796e-04],\n           [ 0.0000e+00, -6.9229e-06,  1.9467e-04]],\n \n          ...,\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -2.2119e-05, -2.7167e-05],\n           [ 0.0000e+00,  2.5827e-04, -1.7880e-04]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -6.9848e-06, -5.7062e-06],\n           [ 0.0000e+00,  2.4320e-05,  1.7141e-05]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00,  2.7535e-05,  1.1488e-05],\n           [ 0.0000e+00,  1.9962e-05, -3.6367e-05]]],\n \n \n         [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00,  5.1348e-04,  5.1171e-04],\n           [ 0.0000e+00,  4.2480e-04,  4.7112e-04]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00,  5.0840e-04,  5.0313e-04],\n           [ 0.0000e+00,  4.8275e-04,  4.4104e-04]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00,  4.5783e-04,  5.4587e-04],\n           [ 0.0000e+00,  5.0573e-04,  4.1074e-04]],\n \n          ...,\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00,  4.7920e-04,  5.1337e-04],\n           [ 0.0000e+00,  1.2693e-04,  5.3722e-04]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00,  5.8644e-04,  4.8128e-04],\n           [ 0.0000e+00,  4.6827e-04,  4.8108e-04]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00,  4.7295e-04,  4.7424e-04],\n           [ 0.0000e+00,  5.0415e-04,  5.2024e-04]]],\n \n \n         [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -2.5716e-04, -2.6008e-04],\n           [ 0.0000e+00, -1.9155e-04, -2.5328e-04]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -2.6592e-04, -2.5870e-04],\n           [ 0.0000e+00, -2.5521e-04, -1.9959e-04]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -2.5014e-04, -2.1563e-04],\n           [ 0.0000e+00, -2.4962e-04, -2.3429e-04]],\n \n          ...,\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -2.4797e-04, -2.5802e-04],\n           [ 0.0000e+00, -1.3467e-04, -2.4528e-04]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -2.5528e-04, -2.4913e-04],\n           [ 0.0000e+00, -2.5662e-04, -2.6106e-04]],\n \n          [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n           [ 0.0000e+00, -2.5573e-04, -2.5476e-04],\n           [ 0.0000e+00, -2.5461e-04, -2.5633e-04]]]]),\n tensor([ 2.9115e-03,  1.5072e-03, -2.3270e-03, -1.3982e-04,  2.7646e-04,\n         -2.4007e-04, -1.9577e-03, -2.9828e-04, -9.6827e-04,  8.7540e-03,\n         -2.8706e-04,  7.0665e-04, -1.3864e-03, -1.9319e-05, -4.9635e-03,\n         -2.9778e-04, -4.1931e-03,  1.9968e-05, -1.5383e-04,  4.4122e-04,\n          1.4704e-04,  1.1390e-03,  2.8023e-03, -4.1801e-03,  3.9691e-04,\n          3.4635e-03, -1.8382e-03, -2.7369e-03, -3.0608e-04, -4.3530e-03,\n          2.7039e-04, -5.0175e-03,  1.9682e-04, -2.5408e-03, -1.4623e-04,\n         -2.1996e-04, -3.4536e-04, -7.2314e-05, -2.6499e-04, -5.6716e-04,\n         -3.0166e-04,  1.7391e-03, -2.3321e-04, -5.2427e-04, -5.7987e-03,\n         -1.4445e-04, -2.9674e-07,  5.8563e-04, -6.8760e-04,  1.6862e-05,\n         -4.9465e-03,  1.2718e-03,  1.0678e-04, -7.8083e-05, -2.9193e-03,\n         -1.4561e-04, -1.1909e-03,  1.9301e-03, -3.2541e-04, -2.1531e-03,\n         -4.9120e-04, -6.7872e-06, -1.1973e-03,  6.1931e-04]),\n tensor([[-0.0073, -0.0024, -0.0044, -0.0093, -0.0093, -0.0091, -0.0053, -0.0092,\n          -0.0069, -0.0088, -0.0083, -0.0090, -0.0064, -0.0097, -0.0081, -0.0092,\n          -0.0053, -0.0090, -0.0094, -0.0091, -0.0092, -0.0078, -0.0061, -0.0070,\n          -0.0095, -0.0087, -0.0039, -0.0073, -0.0057, -0.0067, -0.0091, -0.0066,\n          -0.0091, -0.0049, -0.0094, -0.0093, -0.0092, -0.0096, -0.0091, -0.0096,\n          -0.0092, -0.0054, -0.0093, -0.0092, -0.0089, -0.0091, -0.0091, -0.0057,\n          -0.0091, -0.0091, -0.0076, -0.0043, -0.0092, -0.0091, -0.0084, -0.0091,\n          -0.0088, -0.0042, -0.0037, -0.0088, -0.0093, -0.0076, -0.0061, -0.0095],\n         [ 0.0025,  0.0008,  0.0015,  0.0032,  0.0032,  0.0031,  0.0016,  0.0031,\n           0.0023,  0.0028,  0.0029,  0.0030,  0.0023,  0.0033,  0.0025,  0.0031,\n           0.0023,  0.0031,  0.0032,  0.0030,  0.0031,  0.0024,  0.0020,  0.0028,\n           0.0032,  0.0034,  0.0015,  0.0022,  0.0016,  0.0016,  0.0031,  0.0021,\n           0.0031,  0.0017,  0.0032,  0.0031,  0.0031,  0.0032,  0.0031,  0.0033,\n           0.0032,  0.0018,  0.0031,  0.0031,  0.0034,  0.0030,  0.0030,  0.0019,\n           0.0031,  0.0031,  0.0029,  0.0012,  0.0031,  0.0031,  0.0031,  0.0031,\n           0.0031,  0.0014,  0.0015,  0.0035,  0.0031,  0.0025,  0.0020,  0.0032],\n         [ 0.0016,  0.0002,  0.0011,  0.0019,  0.0019,  0.0018,  0.0013,  0.0018,\n           0.0011,  0.0019,  0.0021,  0.0018,  0.0009,  0.0019,  0.0020,  0.0018,\n           0.0010,  0.0018,  0.0019,  0.0018,  0.0019,  0.0014,  0.0016,  0.0011,\n           0.0019,  0.0021,  0.0009,  0.0012,  0.0011,  0.0020,  0.0018,  0.0017,\n           0.0017,  0.0013,  0.0019,  0.0019,  0.0018,  0.0019,  0.0018,  0.0019,\n           0.0018,  0.0011,  0.0018,  0.0018,  0.0019,  0.0018,  0.0018,  0.0015,\n           0.0018,  0.0018,  0.0009,  0.0010,  0.0018,  0.0018,  0.0016,  0.0018,\n           0.0014,  0.0011,  0.0008,  0.0010,  0.0018,  0.0016,  0.0020,  0.0019],\n         [-0.0074, -0.0019, -0.0048, -0.0090, -0.0090, -0.0088, -0.0055, -0.0089,\n          -0.0067, -0.0087, -0.0075, -0.0088, -0.0062, -0.0093, -0.0078, -0.0089,\n          -0.0055, -0.0088, -0.0091, -0.0088, -0.0089, -0.0080, -0.0054, -0.0065,\n          -0.0093, -0.0084, -0.0042, -0.0072, -0.0058, -0.0072, -0.0088, -0.0064,\n          -0.0088, -0.0051, -0.0091, -0.0091, -0.0090, -0.0093, -0.0088, -0.0093,\n          -0.0090, -0.0047, -0.0089, -0.0089, -0.0079, -0.0089, -0.0089, -0.0053,\n          -0.0089, -0.0089, -0.0072, -0.0045, -0.0089, -0.0089, -0.0084, -0.0088,\n          -0.0077, -0.0041, -0.0035, -0.0080, -0.0090, -0.0078, -0.0063, -0.0091],\n         [-0.0030, -0.0007, -0.0018, -0.0034, -0.0034, -0.0034, -0.0022, -0.0033,\n          -0.0023, -0.0031, -0.0025, -0.0033, -0.0023, -0.0035, -0.0033, -0.0033,\n          -0.0025, -0.0033, -0.0034, -0.0033, -0.0034, -0.0020, -0.0015, -0.0022,\n          -0.0035, -0.0033, -0.0014, -0.0022, -0.0020, -0.0027, -0.0033, -0.0021,\n          -0.0033, -0.0017, -0.0035, -0.0034, -0.0033, -0.0035, -0.0033, -0.0035,\n          -0.0034, -0.0018, -0.0034, -0.0034, -0.0030, -0.0033, -0.0033, -0.0018,\n          -0.0034, -0.0034, -0.0025, -0.0019, -0.0033, -0.0034, -0.0034, -0.0033,\n          -0.0029, -0.0020, -0.0013, -0.0030, -0.0034, -0.0025, -0.0022, -0.0034],\n         [ 0.0042,  0.0011,  0.0025,  0.0048,  0.0048,  0.0048,  0.0031,  0.0048,\n           0.0035,  0.0046,  0.0037,  0.0047,  0.0032,  0.0050,  0.0041,  0.0047,\n           0.0029,  0.0047,  0.0049,  0.0047,  0.0048,  0.0041,  0.0026,  0.0033,\n           0.0050,  0.0045,  0.0018,  0.0035,  0.0032,  0.0042,  0.0047,  0.0030,\n           0.0047,  0.0024,  0.0049,  0.0048,  0.0048,  0.0050,  0.0047,  0.0050,\n           0.0048,  0.0023,  0.0048,  0.0048,  0.0040,  0.0047,  0.0047,  0.0027,\n           0.0048,  0.0048,  0.0038,  0.0026,  0.0048,  0.0047,  0.0046,  0.0047,\n           0.0040,  0.0025,  0.0018,  0.0043,  0.0048,  0.0038,  0.0030,  0.0049],\n         [ 0.0045,  0.0011,  0.0031,  0.0059,  0.0059,  0.0057,  0.0041,  0.0058,\n           0.0038,  0.0057,  0.0050,  0.0057,  0.0040,  0.0061,  0.0053,  0.0057,\n           0.0036,  0.0057,  0.0059,  0.0057,  0.0059,  0.0046,  0.0040,  0.0041,\n           0.0060,  0.0054,  0.0023,  0.0050,  0.0035,  0.0050,  0.0058,  0.0042,\n           0.0057,  0.0032,  0.0060,  0.0059,  0.0058,  0.0061,  0.0057,  0.0061,\n           0.0058,  0.0036,  0.0058,  0.0058,  0.0055,  0.0058,  0.0058,  0.0034,\n           0.0058,  0.0058,  0.0045,  0.0028,  0.0058,  0.0058,  0.0059,  0.0057,\n           0.0053,  0.0029,  0.0024,  0.0048,  0.0059,  0.0046,  0.0043,  0.0059],\n         [ 0.0024,  0.0008,  0.0015,  0.0033,  0.0033,  0.0033,  0.0018,  0.0033,\n           0.0030,  0.0030,  0.0023,  0.0032,  0.0027,  0.0035,  0.0030,  0.0033,\n           0.0024,  0.0033,  0.0034,  0.0033,  0.0033,  0.0030,  0.0015,  0.0023,\n           0.0034,  0.0031,  0.0018,  0.0026,  0.0021,  0.0021,  0.0033,  0.0022,\n           0.0033,  0.0015,  0.0033,  0.0034,  0.0034,  0.0034,  0.0032,  0.0035,\n           0.0034,  0.0015,  0.0034,  0.0033,  0.0027,  0.0033,  0.0033,  0.0015,\n           0.0033,  0.0033,  0.0031,  0.0016,  0.0033,  0.0033,  0.0030,  0.0033,\n           0.0031,  0.0014,  0.0009,  0.0035,  0.0034,  0.0029,  0.0019,  0.0034],\n         [ 0.0054,  0.0016,  0.0032,  0.0061,  0.0061,  0.0059,  0.0036,  0.0060,\n           0.0045,  0.0059,  0.0051,  0.0060,  0.0038,  0.0063,  0.0052,  0.0060,\n           0.0032,  0.0059,  0.0061,  0.0059,  0.0060,  0.0049,  0.0037,  0.0045,\n           0.0062,  0.0055,  0.0023,  0.0045,  0.0038,  0.0050,  0.0059,  0.0041,\n           0.0059,  0.0035,  0.0062,  0.0061,  0.0060,  0.0063,  0.0060,  0.0062,\n           0.0060,  0.0033,  0.0060,  0.0060,  0.0057,  0.0059,  0.0059,  0.0039,\n           0.0060,  0.0060,  0.0047,  0.0032,  0.0060,  0.0059,  0.0055,  0.0059,\n           0.0051,  0.0028,  0.0026,  0.0052,  0.0060,  0.0048,  0.0042,  0.0061],\n         [-0.0028, -0.0007, -0.0019, -0.0034, -0.0034, -0.0033, -0.0024, -0.0033,\n          -0.0023, -0.0033, -0.0029, -0.0033, -0.0020, -0.0035, -0.0030, -0.0033,\n          -0.0021, -0.0033, -0.0034, -0.0033, -0.0033, -0.0026, -0.0024, -0.0023,\n          -0.0035, -0.0035, -0.0013, -0.0024, -0.0018, -0.0032, -0.0033, -0.0022,\n          -0.0033, -0.0018, -0.0035, -0.0033, -0.0033, -0.0035, -0.0033, -0.0035,\n          -0.0034, -0.0018, -0.0033, -0.0033, -0.0032, -0.0033, -0.0033, -0.0021,\n          -0.0034, -0.0034, -0.0026, -0.0016, -0.0033, -0.0033, -0.0034, -0.0033,\n          -0.0026, -0.0017, -0.0015, -0.0026, -0.0034, -0.0024, -0.0026, -0.0034]]),\n tensor([ 0.0224, -0.0076, -0.0045,  0.0217,  0.0082, -0.0117, -0.0141, -0.0081,\n         -0.0146,  0.0081])]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 84
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(convolutionalModelSR2(xTrainingNormalized), yTraining)\n",
    "loss.backward()\n",
    "optimus.getLayersWithGradients()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Important Note**: PyTorch will NOT put the gradients on the parameters until backwards has been called on the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class TrainingSubscriber(StatisticsSubscriber, HookedSubscriber):\n",
    "\n",
    "    def __init__(self,\n",
    "                 lossFunction=torch.nn.functional.cross_entropy,\n",
    "                 schedulingFunctions=[cosineScheduler(1e-1, 1e-6), cosineScheduler(1e-1, 1e-6)], \n",
    "                 optimizationFunctions=[]\n",
    "                 ):\n",
    "        super().__init__(name=\"Training\")\n",
    "        self._optimizer = None\n",
    "        self._optimizationFunctions = optimizationFunctions\n",
    "        self._schedulingFunctions = schedulingFunctions\n",
    "        self._lossFunction = lossFunction\n",
    "\n",
    "    def preModelTeach(self, model, epochs):\n",
    "        super().preModelTeach(model, epochs)\n",
    "        self._optimizer = optim.SGD(model.parameters(), self._schedulingFunctions[0](0))\n",
    "        self._totalEpochs = epochs\n",
    "\n",
    "    def postBatchEvaluation(self, predictions, valdationData):\n",
    "        super().postBatchEvaluation(predictions, valdationData)\n",
    "        calculatedLoss = self._lossFunction(predictions, valdationData)\n",
    "        self._teachModel(calculatedLoss)\n",
    "        self.postBatchLossConsumption(calculatedLoss)\n",
    "\n",
    "    def _teachModel(self, loss):\n",
    "        loss.backward()\n",
    "        self._optimizer.step()\n",
    "        self._optimizer.zero_grad()\n",
    "\n",
    "    def preBatchEvaluation(self):\n",
    "        super().preBatchEvaluation()\n",
    "        self._annealLearningRate()\n",
    "\n",
    "    def _annealLearningRate(self):\n",
    "        for parameterGroup, schedulingFunction in zip(self._optimizer.param_groups, self._schedulingFunctions):\n",
    "            parameterGroup['lr'] = schedulingFunction(self._currentEpoch / self._totalEpochs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class TeacherOptimized:\n",
    "    def __init__(self,\n",
    "                 dataBunch,\n",
    "                 trainingSubscriber: TrainingSubscriber,\n",
    "                 validationSubscriber: ValidationSubscriber):\n",
    "        self._dataBunch = dataBunch\n",
    "        self._trainingSubscriber = trainingSubscriber\n",
    "        self._validationSubscriber = validationSubscriber\n",
    "\n",
    "    def teachModel(self, model, numberOfEpochs):\n",
    "        self._notifiyPreTeach(model, numberOfEpochs)\n",
    "        for epoch in range(numberOfEpochs):\n",
    "            self._trainModel(model,\n",
    "                             epoch)\n",
    "            self._validateModel(model,\n",
    "                                epoch)\n",
    "        self._notifiyPostTaught()\n",
    "\n",
    "    def _notifiyPreTeach(self, model, epochs):\n",
    "        self._trainingSubscriber.preModelTeach(model, epochs)\n",
    "        self._validationSubscriber.preModelTeach(model, epochs)\n",
    "\n",
    "    def _notifiyPostTaught(self):\n",
    "        self._trainingSubscriber.postModelTeach()\n",
    "        self._validationSubscriber.postModelTeach()\n",
    "\n",
    "    def _trainModel(self, model, epoch):\n",
    "        self._processData(model,\n",
    "                          self._dataBunch.trainingDataSet,\n",
    "                          epoch,\n",
    "                          self._trainingSubscriber)\n",
    "\n",
    "    def _validateModel(self, model, epoch):\n",
    "        with torch.no_grad():\n",
    "            self._processData(model,\n",
    "                              self._dataBunch.validationDataSet,\n",
    "                              epoch,\n",
    "                              self._validationSubscriber)\n",
    "\n",
    "    def _processData(self,\n",
    "                     model,\n",
    "                     dataLoader,\n",
    "                     epoch,\n",
    "                     processingSubscriber: Subscriber):\n",
    "        processingSubscriber.preEpoch(epoch, dataLoader)\n",
    "        try:\n",
    "            for _xDataBatch, _yDataBatch in dataLoader:\n",
    "                processingSubscriber.preBatchEvaluation()\n",
    "                _predictions = model(_xDataBatch)\n",
    "                processingSubscriber.postBatchEvaluation(_predictions, _yDataBatch)\n",
    "        except ProcessCancellationException: pass\n",
    "        finally:\n",
    "            processingSubscriber.postEpoch(epoch)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "validationSubscriber = ValidationSubscriber()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "trainingSubscriber = TrainingSubscriber()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "teacher = TeacherEnhanced(imageDataBunch, \n",
    "                          trainingSubscriber,\n",
    "                          validationSubscriber\n",
    "                         )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "convolutionalModelSR1 = createBetterConvolutionModel(numberOfClasses, layerSizes)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.0990)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 22
    }
   ],
   "source": [
    "accuracy(convolutionalModelSR1(validationDataSet.xVector), validationDataSet.yVector)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch #0 Training: Loss 2.301060914993286 Accuracy 0.1177348718047142\n",
      "Epoch #0 Validation: Loss 0.0 Accuracy 0.1890822798013687\n",
      "Epoch #1 Training: Loss 1.7400457859039307 Accuracy 0.41401273012161255\n",
      "Epoch #1 Validation: Loss 0.0 Accuracy 0.7901503443717957\n",
      "Epoch #2 Training: Loss 0.5095152258872986 Accuracy 0.8572850227355957\n",
      "Epoch #2 Validation: Loss 0.0 Accuracy 0.8803402185440063\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "teacher.teachModel(convolutionalModelSR1, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "accuracy(convolutionalModelSR1(validationDataSet.xVector), validationDataSet.yVector)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   },
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.8797)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 24
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}