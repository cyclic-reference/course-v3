{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from dataclasses import dataclass\n",
    "from functools import reduce, partial\n",
    "import torch\n",
    "from torch import optim\n",
    "from nbs.dl2.exp.nb_02 import getMnistData, assertNearZero\n",
    "from nbs.dl2.exp.nb_03 import Dataset, createDataLoaders, accuracy\n",
    "from nbs.dl2.exp.nb_04 import DataBunch\n",
    "from nbs.dl2.exp.nb_05 import aggregateSchedulers, createCosineSchedulers, cosineScheduler\n",
    "from nbs.dl2.exp.nb_06 import normalizeVectors, createBetterConvolutionModel\n",
    "from nbs.dl2.exp.nb_07D import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "xTraining, yTraining, xValidation, yValidation = getMnistData()\n",
    "xTrainingNormalized, xValidationNormalized = \\\n",
    "    normalizeVectors(xTraining, xValidation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "assertNearZero(xTrainingNormalized.mean())\n",
    "assertNearZero(xValidationNormalized.mean())\n",
    "assertNearZero(1 - xTrainingNormalized.std())\n",
    "assertNearZero(1 - xValidationNormalized.std())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "layerSizes = [8, 16, 32, 64, 64]\n",
    "numberOfClasses = 10\n",
    "hiddenLayerSize = 75\n",
    "batchSize = 64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "trainingDataSet, validationDataSet = Dataset(xTrainingNormalized[:10000], yTraining[:10000]), Dataset(xValidationNormalized[:10000], yValidation[:10000])\n",
    "trainingDataLoader, validationDataLoader = createDataLoaders(trainingDataSet, validationDataSet, batchSize)\n",
    "imageDataBunch = DataBunch(trainingDataLoader, validationDataLoader, numberOfClasses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class ProcessCancellationException(Exception): pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def composeFunctions(funInput, functions): \n",
    "    return reduce(lambda accum, function: function(accum), \n",
    "                  functions, \n",
    "                  funInput)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "result = composeFunctions(0, [\n",
    "    lambda x: x + 1,\n",
    "    lambda x: x + 2,\n",
    "    lambda x: x + 3,\n",
    "])\n",
    "\n",
    "assert result == 6, \"Composition is wrong\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HyperParameters:\n",
    "    learningRate: float"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#export\n",
    "def flatMap(function, items):\n",
    "    return reduce(lambda accum, manyItems: accum + manyItems,\n",
    "           list(map(function, items)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "result = flatMap(lambda n: list(map(lambda _: n+1, range(n+1))), \n",
    "        list(range(3)))\n",
    "\n",
    "assert result == [1, 2, 2, 3, 3, 3], \"Flat map did not work\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class OptimizationFunction:\n",
    "    \n",
    "    def __call__(self, \n",
    "                 modelLayer, \n",
    "                 hyperParameters: HyperParameters):\n",
    "        return hyperParameters\n",
    "    \n",
    "class LearningRateAnnealer(OptimizationFunction):\n",
    "    def __init__(self, learningRateSupplier)-> None:\n",
    "        self._learningRateSupplier = learningRateSupplier\n",
    "        \n",
    "    def __call__(self, modelLayer, hyperParameters: HyperParameters):\n",
    "        hyperParameters.learningRate = self._learningRateSupplier()\n",
    "        return super().__call__(modelLayer, hyperParameters)\n",
    "    \n",
    "class LearningRateOptimizer(OptimizationFunction):\n",
    "    def __call__(self, \n",
    "                 modelLayer, \n",
    "                 hyperParameters: HyperParameters):\n",
    "        modelLayer.data.add_(-hyperParameters.learningRate, modelLayer.grad.data)\n",
    "        return super().__call__(modelLayer, hyperParameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, modelParameters, \n",
    "                 optimizationFunctions,\n",
    "                 hyperParameters: HyperParameters=HyperParameters(0.5)):\n",
    "        super().__init__()\n",
    "        self._modelParameters = list(modelParameters)\n",
    "        self._hyperParameters = [hyperParameters for _ in self._modelParameters]\n",
    "        self._optimizationFunctions = optimizationFunctions\n",
    "        \n",
    "    def getLayersWithGradients(self):\n",
    "        return list(filter(lambda modelAndHyperParameters: modelAndHyperParameters[0].grad is not None, \n",
    "                           zip(self._modelParameters, self._hyperParameters)))\n",
    "    \n",
    "    def resetGradients(self):\n",
    "        for modelParameter, _ in self.getLayersWithGradients():\n",
    "            modelParameter.grad.detach_()\n",
    "            modelParameter.grad.zero_()\n",
    "    \n",
    "    def optimizeModel(self):\n",
    "        for modelParameter, hyperParameter in self.getLayersWithGradients():\n",
    "            composeFunctions(hyperParameter, \n",
    "                             map(lambda fun: partial(fun, modelParameter), \n",
    "                                 self._optimizationFunctions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "convolutionalModelSR2 = createBetterConvolutionModel(numberOfClasses, layerSizes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 17
    }
   ],
   "source": [
    "optimus = Optimizer(convolutionalModelSR2.parameters(), [])\n",
    "len(optimus.getLayersWithGradients())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "12"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 18
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(convolutionalModelSR2(xTrainingNormalized), yTraining)\n",
    "loss.backward()\n",
    "len(optimus.getLayersWithGradients())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "class LearningRateRecorder:\n",
    "    def __init__(self, \n",
    "                 learningRateSupplier=lambda:0.5):\n",
    "        super().__init__()\n",
    "        self._aggregatedLearningRates = []\n",
    "        self._learningRateSupplier = learningRateSupplier\n",
    "    def __call__(self):\n",
    "        learningRateReturned = self._learningRateSupplier()\n",
    "        self._aggregatedLearningRates.append(learningRateReturned)\n",
    "        return learningRateReturned\n",
    "    \n",
    "    def plotLearningRates(self):\n",
    "        plotter.plot(self._aggregatedLearningRates)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Important Note**: PyTorch will NOT put the gradients on the parameters until backwards has been called on the model    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# todo: learning rate recording\n",
    "class TrainingSubscriber(StatisticsSubscriber, \n",
    "                         HookedSubscriber):\n",
    "\n",
    "    def __init__(self,\n",
    "                 lossFunction=torch.nn.functional.cross_entropy,\n",
    "                 schedulingFunction=cosineScheduler(1e-1, 1e-6), \n",
    "                 optimizationFunctions=[]\n",
    "                 ):\n",
    "        super().__init__(name=\"Training\")\n",
    "        self._optimizer: Optimizer = None\n",
    "        self._optimizationFunctions = optimizationFunctions\n",
    "        self._schedulingFunction = schedulingFunction\n",
    "        self._lossFunction = lossFunction\n",
    "        \n",
    "        self._learningRateRecorder = LearningRateRecorder()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def plotLearningRate(self):\n",
    "        self._learningRateRecorder.plotLearningRates()\n",
    "        \n",
    "    def getOptimizationFunctions(self):\n",
    "        self._learningRateRecorder = LearningRateRecorder(lambda: self._schedulingFunction(self._currentEpoch / self._totalEpochs) )\n",
    "        return [\n",
    "            LearningRateAnnealer(self._learningRateRecorder),\n",
    "            LearningRateOptimizer()  \n",
    "        ]\n",
    "\n",
    "    def preModelTeach(self, model, epochs):\n",
    "        super().preModelTeach(model, epochs)\n",
    "        self._optimizer = Optimizer(model.parameters(), \n",
    "                                    self.getOptimizationFunctions(),\n",
    "                                    HyperParameters(\n",
    "                                        learningRate=self._schedulingFunction(0)\n",
    "                                    ))\n",
    "        self._totalEpochs = epochs\n",
    "\n",
    "    def postBatchEvaluation(self, predictions, validationData):\n",
    "        super().postBatchEvaluation(predictions, validationData)\n",
    "        calculatedLoss = self._lossFunction(predictions, validationData)\n",
    "        self._teachModel(calculatedLoss)\n",
    "        self.postBatchLossConsumption(calculatedLoss)\n",
    "\n",
    "    def _teachModel(self, loss):\n",
    "        loss.backward() # adds auto gradients to model parameters\n",
    "        self._optimizer.optimizeModel()\n",
    "        self._optimizer.resetGradients() "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "class TeacherOptimized:\n",
    "    def __init__(self,\n",
    "                 dataBunch,\n",
    "                 trainingSubscriber: TrainingSubscriber,\n",
    "                 validationSubscriber: ValidationSubscriber):\n",
    "        self._dataBunch = dataBunch\n",
    "        self._trainingSubscriber = trainingSubscriber\n",
    "        self._validationSubscriber = validationSubscriber\n",
    "\n",
    "    def teachModel(self, model, numberOfEpochs):\n",
    "        self._notifiyPreTeach(model, numberOfEpochs)\n",
    "        for epoch in range(numberOfEpochs):\n",
    "            self._trainModel(model,\n",
    "                             epoch)\n",
    "            self._validateModel(model,\n",
    "                                epoch)\n",
    "        self._notifiyPostTaught()\n",
    "\n",
    "    def _notifiyPreTeach(self, model, epochs):\n",
    "        self._trainingSubscriber.preModelTeach(model, epochs)\n",
    "        self._validationSubscriber.preModelTeach(model, epochs)\n",
    "\n",
    "    def _notifiyPostTaught(self):\n",
    "        self._trainingSubscriber.postModelTeach()\n",
    "        self._validationSubscriber.postModelTeach()\n",
    "\n",
    "    def _trainModel(self, model, epoch):\n",
    "        self._processData(model,\n",
    "                          self._dataBunch.trainingDataSet,\n",
    "                          epoch,\n",
    "                          self._trainingSubscriber)\n",
    "\n",
    "    def _validateModel(self, model, epoch):\n",
    "        with torch.no_grad():\n",
    "            self._processData(model,\n",
    "                              self._dataBunch.validationDataSet,\n",
    "                              epoch,\n",
    "                              self._validationSubscriber)\n",
    "\n",
    "    def _processData(self,\n",
    "                     model,\n",
    "                     dataLoader,\n",
    "                     epoch,\n",
    "                     processingSubscriber: Subscriber):\n",
    "        processingSubscriber.preEpoch(epoch, dataLoader)\n",
    "        try:\n",
    "            for _xDataBatch, _yDataBatch in dataLoader:\n",
    "                processingSubscriber.preBatchEvaluation()\n",
    "                _predictions = model(_xDataBatch)\n",
    "                processingSubscriber.postBatchEvaluation(_predictions, _yDataBatch)\n",
    "        except ProcessCancellationException: pass\n",
    "        finally:\n",
    "            processingSubscriber.postEpoch(epoch)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "#export\n",
    "def createCosineScheduler(start, high, end):\n",
    "    return [cosineScheduler(start, high), cosineScheduler(high, end)]\n",
    "\n",
    "def createWeightAndBiasSchedulers():\n",
    "    phases = [0.3, 0.7]\n",
    "    _weightsScheduler = aggregateSchedulers(phases, createCosineScheduler(0.3, 0.6, 0.2)) \n",
    "    _biasScheduler = aggregateSchedulers(phases, createCosineScheduler(0.9, 1.8, 0.6))\n",
    "    return _weightsScheduler, _biasScheduler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "validationSubscriber = ValidationSubscriber()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "weightScheduler, biasScheduler = createWeightAndBiasSchedulers()\n",
    "\n",
    "trainingSubscriber = TrainingSubscriber(schedulingFunction=weightScheduler)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "teacher = TeacherEnhanced(imageDataBunch, \n",
    "                          trainingSubscriber,\n",
    "                          validationSubscriber\n",
    "                         )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "convolutionalModelSR1 = createBetterConvolutionModel(numberOfClasses, layerSizes)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.1009)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 68
    }
   ],
   "source": [
    "accuracy(convolutionalModelSR1(validationDataSet.xVector), validationDataSet.yVector)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch #0 Training: Loss 1.6901013851165771 Accuracy 0.36713773012161255\n",
      "Epoch #0 Validation: Loss 0.0 Accuracy 0.8657041192054749\n",
      "Epoch #1 Training: Loss 0.3980051577091217 Accuracy 0.8794785141944885\n",
      "Epoch #1 Validation: Loss 0.0 Accuracy 0.9266218543052673\n",
      "Epoch #2 Training: Loss 0.11377991735935211 Accuracy 0.9655652642250061\n",
      "Epoch #2 Validation: Loss 0.0 Accuracy 0.9659810066223145\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "teacher.teachModel(convolutionalModelSR1, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "accuracy(convolutionalModelSR1(validationDataSet.xVector), validationDataSet.yVector)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   },
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.9656)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 70
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainingSubscriber.plotLearningRate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Things to look at later\n",
    "\n",
    "- Learning Rate Capping\n",
    "- Bias Learning rate annealing\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}