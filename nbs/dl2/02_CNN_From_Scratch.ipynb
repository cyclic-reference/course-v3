{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_01 import *\n",
    "\n",
    "def getMnistData():\n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(lambda data: tensor(data).cuda(), (x_train,y_train,x_valid,y_valid))\n",
    "\n",
    "def normalizeVector(vectorToNormalize, vectorMean, vectorStandardDeviation): \n",
    "    return (vectorToNormalize-vectorMean)/vectorStandardDeviation\n",
    "\n",
    "def assertNearZero(someScalar,tol=1e-3): assert someScalar.abs()<tol, f\"Near zero: {someScalar}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearCombination(vector, matrix, biasVector): return vector @ matrix + biasVector\n",
    "def reLU(vector): return vector.clamp_min(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math Translation**\n",
    "\n",
    "- **x** is the values that we are given (in this case it is a bunch of vectors that repersent images of numbers)\n",
    "- **y** is the expected values that we want to predict (eg, is the image a \"1\" or \"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrainingSet, yTrainingSet, xValidationSet, yValidationSet = getMnistData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization\n",
    "\n",
    "Data needs to be [normalized](https://en.wikipedia.org/wiki/Normalization_(statistics)) so that it reduces the impact of outliers on the data set.\n",
    "\n",
    "One standard normaliziation is [standard score](https://en.wikipedia.org/wiki/Standard_score) which gives the data set a Gaussian Bell curve characteristic.\n",
    "\n",
    "**This is how we will normalize the image data**\n",
    "\n",
    "\n",
    "$$normalizedStandardScore ={value-mean  \\over standardDeviation }$$\n",
    "\n",
    "or in nerd words\n",
    "\n",
    "$$z ={x-\\mu \\over \\sigma}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrainingSetMean, xTrainingSetStandardDeviation = xTrainingSet.mean(), xTrainingSet.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1304, device='cuda:0'), tensor(0.3073, device='cuda:0'))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xTrainingSetMean, xTrainingSetStandardDeviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time to normalize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrainingSetNormalized = normalizeVector(xTrainingSet, xTrainingSetMean, xTrainingSetStandardDeviation).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "xValidationSetNormalized = normalizeVector(xValidationSet, xValidationSet.mean(), xValidationSet.std()).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data has been normalized, we would expect the mean of the normalized data to be somewhere around zero, like the bell curve would assume.\n",
    "\n",
    "![Bell Curve](./images/The_Normal_Distribution.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertNearZero(xTrainingSetNormalized.mean())\n",
    "assertNearZero(xValidationSetNormalized.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The standard deviation, or $\\sigma$ (sigma), of a **normalized distribution** should be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertNearZero(1 - xTrainingSetNormalized.std())\n",
    "assertNearZero(1 - xValidationSetNormalized.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Side Note**\n",
    "\n",
    "Just because the data is normalized, does not change the fact that the images remain intact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change default color to plasma\n",
    "plotter.rcParams['image.cmap'] = 'plasma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f94592bdf60>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter.imshow(xTrainingSet[69].cpu().view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9459265080>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter.imshow(xTrainingSetNormalized[69].cpu().view(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capture Data Set Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10, device='cuda:0'))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xRows, xColumns = xTrainingSetNormalized.shape\n",
    "inputChannels = yTrainingSet.max() + 1\n",
    "(xRows, xColumns, inputChannels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfHiddenNodes = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer Initialization\n",
    "\n",
    "Setting each layer in our convolutional network is important. Getting the right set of inital weights can lead to really good outputs. The following layer (done below) will have referenced the paper [Delving Deep into Rectifiers](https://arxiv.org/abs/1502.01852).\n",
    "\n",
    "Paper Dictonary\n",
    "---\n",
    "- $c$ - Number of Input Channels\n",
    "- $\\operatorname {Var} [\\vec{v}]$ - Variance of input vector, aka $\\sigma ^{2}$ (sigma squared), \n",
    "- $\\operatorname {E} [\\vec{v}]$ - Mean of itput vector, aka $\\mu$ (mu)\n",
    "- $b$ - Bias Vector\n",
    "- $n$ - Number of Columns\n",
    "\n",
    "##### Section 2.2 Synopsis\n",
    "Your weighted matrices should be initilaized such that the mean should be zero and the rest are symetrically dispresed around that mean (eg normalized)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple Initialization**\n",
    "\n",
    "Dividing the tensor by the number of total inputs of the each image brings the mean way down to zero. The distribution is also expected to have a standard deviation $\\sigma$ (sigma) of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightedLayerOne = (torch.randn(xColumns, numberOfHiddenNodes) / math.sqrt(xColumns)).cuda()\n",
    "weightedLayerTwo = (torch.randn(numberOfHiddenNodes, 1) / math.sqrt(numberOfHiddenNodes)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertNearZero(weightedLayerOne.mean())\n",
    "assertNearZero(weightedLayerOne.std() - 1/math.sqrt(xColumns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We also initialize $b$ = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "biasVectorLayerOne = torch.zeros(numberOfHiddenNodes).cuda()\n",
    "biasVectorLayerTwo = torch.zeros(1).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any linear combination of the initialized layers should have a $\\mu$=0 and $\\sigma$=1 because $y$ is just a linear combination of $\\vec{x}W + \\vec{b}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertNearZero(xValidationSetNormalized.mean())\n",
    "assertNearZero(1 - xValidationSetNormalized.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 784]), torch.Size([784, 50]))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xValidationSetNormalized.shape, weightedLayerOne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearWomboCombo = linearCombination(xValidationSetNormalized, weightedLayerOne, biasVectorLayerOne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaiming Note:**\n",
    "These should be close to zero because of our initializaitons, but this appears to not be the case.\n",
    "\n",
    "_The same goes for `reLU` processed vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0870, device='cuda:0'), tensor(0.9629, device='cuda:0'))"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearWomboCombo.mean(), linearWomboCombo.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "reLUWomboCombo = reLU(linearCombination(xValidationSetNormalized, weightedLayerOne, biasVectorLayerOne))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4239, device='cuda:0'), tensor(0.6024, device='cuda:0'))"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reLUWomboCombo.mean(), reLUWomboCombo.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paper Revelation**\n",
    "\n",
    "Apparently scaling the intialization matrix down by dividing it by it's standard deviation apparently helps a bunch.\n",
    "\n",
    ">This leads to a zero-mean Gaussian distribution whose standard deviation (std) is $\\sqrt {2/n}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaimingInitializedWeightedMatrixOne = (torch.randn(xColumns, numberOfHiddenNodes) * math.sqrt(2/xColumns)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertNearZero(kaimingInitializedWeightedMatrixOne.mean())\n",
    "assertNearZero(kaimingInitializedWeightedMatrixOne.std() - 1 * math.sqrt(2/xColumns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Success!**\n",
    "Now we get to use the library method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraryKiamingWeightedMatrix = torch.zeros(xColumns, numberOfHiddenNodes).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "init.kaiming_normal_(libraryKiamingWeightedMatrix, mode='fan_out')\n",
    "assertNearZero(libraryKiamingWeightedMatrix.mean())\n",
    "assertNearZero(libraryKiamingWeightedMatrix.std() - 1 * math.sqrt(2/xColumns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "testMatrix = torch.zeros(xColumns, numberOfHiddenNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407 µs ± 172 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit init.kaiming_normal_(testMatrix, mode='fan_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428 µs ± 214 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit torch.randn(xColumns, numberOfHiddenNodes) * math.sqrt(2/xColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting closer to Ideal\n",
    "\n",
    "Apparently the Ideal state for our outputs ofter reLU transformation is to have a mean of zero\n",
    "    $$\\mu \\approx 0$$\n",
    "And a standard deviation of one\n",
    "    $$\\sigma \\approx 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "forwardPass = reLU(linearCombination(xValidationSetNormalized, \n",
    "                                     libraryKiamingWeightedMatrix, \n",
    "                                     biasVectorLayerOne))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5487, device='cuda:0'), tensor(0.8239, device='cuda:0'))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forwardPass.mean(), forwardPass.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f94591d2128>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter.scatter(x=range(numberOfHiddenNodes), y=forwardPass[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reLUEnhanced(vector): return vector.clamp_min(0.) - 0.5 # moves all the points above zero down to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhancedForwardPass = reLUEnhanced(linearCombination(xValidationSetNormalized, \n",
    "                                                     libraryKiamingWeightedMatrix, \n",
    "                                                     biasVectorLayerOne))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shifting closer to zero**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f945919fa58>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter.scatter(x=range(numberOfHiddenNodes), y=enhancedForwardPass[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0487, device='cuda:0'), tensor(0.8239, device='cuda:0'))"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhancedForwardPass.mean(), enhancedForwardPass.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalLibraryKiamingWeightedMatrix = torch.zeros(numberOfHiddenNodes, 1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dun\n"
     ]
    }
   ],
   "source": [
    "init.kaiming_normal_(finalLibraryKiamingWeightedMatrix, mode='fan_out')\n",
    "print('dun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Forward Pass CNN Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at what the input matrix's shape will be and then observe how the 2 weighted convolution matrices' shapes play into that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 784]), torch.Size([784, 50]), torch.Size([50, 1]))"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrainingSetNormalized.shape, libraryKiamingWeightedMatrix.shape, finalLibraryKiamingWeightedMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleModel(inputMatrix):\n",
    "    firstActivations = linearCombination(inputMatrix, \n",
    "                                         libraryKiamingWeightedMatrix, \n",
    "                                         biasVectorLayerOne)\n",
    "    clampedFirstActivations = reLUEnhanced(firstActivations)\n",
    "    lastActivations = linearCombination(clampedFirstActivations, \n",
    "                                        finalLibraryKiamingWeightedMatrix, \n",
    "                                        biasVectorLayerTwo)\n",
    "    return lastActivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.08 ms, sys: 0 ns, total: 1.08 ms\n",
      "Wall time: 859 µs\n"
     ]
    }
   ],
   "source": [
    "%time predictions = simpleModel(xTrainingSetNormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert predictions.shape == torch.Size([xTrainingSetNormalized.shape[0], 1]), \"{} does not equal {}\".format(predictions.shape, torch.Size([xTrainingSetNormalized.shape[0], 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready to learn!\n",
    "**Loss function**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def assertSameShape(actualVector, expectedVector):\n",
    "    assert actualVector.shape == expectedVector.shape, \"Input vectors do not have the same shape! {} and {}\".format(actualVector.shape, expectedVector.shape)\n",
    "def meanSquaredError(actualVector, expectedVector):\n",
    "    assertSameShape(actualVector, expectedVector)\n",
    "    return (actualVector - expectedVector).pow(2).mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1.72 ms, total: 1.72 ms\n",
      "Wall time: 861 µs\n"
     ]
    }
   ],
   "source": [
    "%time loss = meanSquaredError(predictions.squeeze(-1), yTrainingSet.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32.3895, device='cuda:0')"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal now is to minimize error, and we can do this by the process of backwards propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taking the deriviative (finding the gradient of the slope) of the loss function**\n",
    "\n",
    "*quick note*: `unsqueeze(-1)` will add a dimension to a vector eg `size([4])` -> `size([4, 1])` after unsqueezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanSquaredErrorGradient(actualVector, expectedVector):\n",
    "    squeezedActualVector = actualVector.squeeze(-1)\n",
    "    assertSameShape(squeezedActualVector, expectedVector)\n",
    "    lossVector = (squeezedActualVector - expectedVector)\n",
    "    actualVector.storedGradients = 2. * lossVector.unsqueeze(-1) / squeezedActualVector.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reLUErrorGradient(previousActivations, nextActivations):\n",
    "    previousActivations.storedGradients = (previousActivations > 0).float() * nextActivations.storedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearCombinationErrorGradient(inputMatrix, activationMatrix, weightedMatrix, biasVector):\n",
    "    inputMatrix.storedGradients = activationMatrix.storedGradients @ weightedMatrix.t() # t for transpose\n",
    "    print((inputMatrix.shape, activationMatrix.shape))\n",
    "    weightedMatrixGradients = (inputMatrix.unsqueeze(-1) * activationMatrix.storedGradients).sum(0)\n",
    "    weightedMatrix.storedGradients = weightedMatrixGradients\n",
    "    biasVector.storedGradients = activationMatrix.storedGradients.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def churnThenLearn(testInputs, validationOutputs):\n",
    "    #Churn\n",
    "    firstLayerActivations = linearCombination(testInputs, \n",
    "                                              libraryKiamingWeightedMatrix, \n",
    "                                              biasVectorLayerOne)\n",
    "    clampedFirstActivations = reLUEnhanced(firstLayerActivations)\n",
    "    finalLayerActivations = linearCombination(clampedFirstActivations, \n",
    "                                              finalLibraryKiamingWeightedMatrix, \n",
    "                                              biasVectorLayerTwo)\n",
    "    \n",
    "    loss = meanSquaredError(finalLayerActivations.squeeze(-1), validationOutputs)\n",
    "    print(\"Loss = {}\".format(loss))\n",
    "    \n",
    "    #Learn\n",
    "    meanSquaredErrorGradient(finalLayerActivations, validationOutputs)\n",
    "    linearCombinationErrorGradient(clampedFirstActivations, \n",
    "                                   finalLayerActivations, \n",
    "                                   finalLibraryKiamingWeightedMatrix,\n",
    "                                   biasVectorLayerTwo)\n",
    "    reLUErrorGradient(firstLayerActivations, finalLayerActivations)\n",
    "    linearCombinationErrorGradient(firstLayerActivations, \n",
    "                                   clampedFirstActivations, \n",
    "                                   libraryKiamingWeightedMatrix, \n",
    "                                   biasVectorLayerOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraryKiamingWeightedMatrix.storedGradients,biasVectorLayerOne.storedGradients,finalLibraryKiamingWeightedMatrix.storedGradients,biasVectorLayerTwo.storedGradients = [None]*4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 32.38948059082031\n",
      "(torch.Size([50000, 50]), torch.Size([50000, 1]))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (50) must match the size of tensor b (50000) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-320-cee15bece0f9>\u001b[0m in \u001b[0;36mchurnThenLearn\u001b[0;34m(testInputs, validationOutputs)\u001b[0m\n\u001b[1;32m     17\u001b[0m                                    \u001b[0mfinalLayerActivations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                    \u001b[0mfinalLibraryKiamingWeightedMatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                                    biasVectorLayerTwo)\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mreLUErrorGradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirstLayerActivations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalLayerActivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     linearCombinationErrorGradient(firstLayerActivations, \n",
      "\u001b[0;32m<ipython-input-319-57c6362cbb88>\u001b[0m in \u001b[0;36mlinearCombinationErrorGradient\u001b[0;34m(inputMatrix, activationMatrix, weightedMatrix, biasVector)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minputMatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoredGradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivationMatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoredGradients\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mweightedMatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# t for transpose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputMatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivationMatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mweightedMatrixGradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputMatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mactivationMatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoredGradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mweightedMatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoredGradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweightedMatrixGradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbiasVector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoredGradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivationMatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoredGradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (50) must match the size of tensor b (50000) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "%time churnThenLearn(xTrainingSetNormalized, yTrainingSet.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
