{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_01 import *\n",
    "\n",
    "def getMnistData():\n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(lambda data: tensor(data).cuda(), (x_train,y_train,x_valid,y_valid))\n",
    "\n",
    "def normalizeVector(vectorToNormalize, vectorMean, vectorStandardDeviation): \n",
    "    return (vectorToNormalize-vectorMean)/vectorStandardDeviation\n",
    "\n",
    "def assertNearZero(someScalar,tol=1e-3): assert someScalar.abs()<tol, f\"Near zero: {someScalar}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearCombination(vector, matrix, biasVector): return vector @ matrix + biasVector\n",
    "def reLU(vector): return vector.clamp_min(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math Translation**\n",
    "\n",
    "- **x** is the values that we are given (in this case it is a bunch of vectors that repersent images of numbers)\n",
    "- **y** is the expected values that we want to predict (eg, is the image a \"1\" or \"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrainingSet, yTrainingSet, xValidationSet, yValidationSet = getMnistData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization\n",
    "\n",
    "Data needs to be [normalized](https://en.wikipedia.org/wiki/Normalization_(statistics)) so that it reduces the impact of outliers on the data set.\n",
    "\n",
    "One standard normaliziation is [standard score](https://en.wikipedia.org/wiki/Standard_score) which gives the data set a Gaussian Bell curve characteristic.\n",
    "\n",
    "**This is how we will normalize the image data**\n",
    "\n",
    "\n",
    "$$normalizedStandardScore ={value-mean  \\over standardDeviation }$$\n",
    "\n",
    "or in nerd words\n",
    "\n",
    "$$z ={x-\\mu \\over \\sigma}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrainingSetMean, xTrainingSetStandardDeviation = xTrainingSet.mean(), xTrainingSet.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1304, device='cuda:0'), tensor(0.3073, device='cuda:0'))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xTrainingSetMean, xTrainingSetStandardDeviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time to normalize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrainingSetNormalized = normalizeVector(xTrainingSet, xTrainingSetMean, xTrainingSetStandardDeviation).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "xValidationSetNormalized = normalizeVector(xValidationSet, xValidationSet.mean(), xValidationSet.std()).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data has been normalized, we would expect the mean of the normalized data to be somewhere around zero, like the bell curve would assume.\n",
    "\n",
    "![Bell Curve](./images/The_Normal_Distribution.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertNearZero(xTrainingSetNormalized.mean())\n",
    "assertNearZero(xValidationSetNormalized.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The standard deviation, or $\\sigma$ (sigma), of a **normalized distribution** should be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertNearZero(1 - xTrainingSetNormalized.std())\n",
    "assertNearZero(1 - xValidationSetNormalized.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Side Note**\n",
    "\n",
    "Just because the data is normalized, does not change the fact that the images remain intact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change default color to plasma\n",
    "plotter.rcParams['image.cmap'] = 'plasma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2693f72438>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter.imshow(xTrainingSet[69].cpu().view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2693f6e780>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter.imshow(xTrainingSetNormalized[69].cpu().view(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capture Data Set Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10, device='cuda:0'))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xRows, xColumns = xTrainingSetNormalized.shape\n",
    "inputChannels = yTrainingSet.max() + 1\n",
    "(xRows, xColumns, inputChannels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfHiddenNodes = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer Initialization\n",
    "\n",
    "Setting each layer in our convolutional network is important. Getting the right set of inital weights can lead to really good outputs. The following layer (done below) will have referenced the paper [Delving Deep into Rectifiers](https://arxiv.org/abs/1502.01852).\n",
    "\n",
    "Paper Dictonary\n",
    "---\n",
    "- $c$ - Number of Input Channels\n",
    "- $\\operatorname {Var} [\\vec{v}]$ - Variance of input vector, aka $\\sigma ^{2}$ (sigma squared), \n",
    "- $\\operatorname {E} [\\vec{v}]$ - Mean of itput vector, aka $\\mu$ (mu)\n",
    "- $b$ - Bias Vector\n",
    "- $n$ - Number of Columns\n",
    "\n",
    "##### Section 2.2 Synopsis\n",
    "Your weighted matrices should be initilaized such that the mean should be zero and the rest are symetrically dispresed around that mean (eg normalized)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple Initialization**\n",
    "\n",
    "Dividing the tensor by the number of total inputs of the each image brings the mean way down to zero. The distribution is also expected to have a standard deviation $\\sigma$ (sigma) of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightedLayerOne = (torch.randn(xColumns, numberOfHiddenNodes) / math.sqrt(xColumns)).cuda()\n",
    "weightedLayerTwo = (torch.randn(numberOfHiddenNodes, 1) / math.sqrt(numberOfHiddenNodes)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertNearZero(weightedLayerOne.mean())\n",
    "assertNearZero(weightedLayerOne.std() - 1/math.sqrt(xColumns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We also initialize $b$ = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "biasVectorLayerOne = torch.zeros(numberOfHiddenNodes).cuda()\n",
    "biasVectorLayerTwo = torch.zeros(1).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any linear combination of the initialized layers should have a $\\mu$=0 and $\\sigma$=1 because $y$ is just a linear combination of $\\vec{x}W + \\vec{b}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertNearZero(xValidationSetNormalized.mean())\n",
    "assertNearZero(1 - xValidationSetNormalized.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 784]), torch.Size([784, 50]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xValidationSetNormalized.shape, weightedLayerOne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearWomboCombo = linearCombination(xValidationSetNormalized, weightedLayerOne, biasVectorLayerOne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaiming Note:**\n",
    "These should be close to zero because of our initializaitons, but this appears to not be the case.\n",
    "\n",
    "_The same goes for `reLU` processed vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1179, device='cuda:0'), tensor(1.0075, device='cuda:0'))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearWomboCombo.mean(), linearWomboCombo.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "reLUWomboCombo = reLU(linearCombination(xValidationSetNormalized, weightedLayerOne, biasVectorLayerOne))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4602, device='cuda:0'), tensor(0.6286, device='cuda:0'))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reLUWomboCombo.mean(), reLUWomboCombo.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paper Revelation**\n",
    "\n",
    "Apparently scaling the intialization matrix down by dividing it by it's standard deviation apparently helps a bunch.\n",
    "\n",
    ">This leads to a zero-mean Gaussian distribution whose standard deviation (std) is $\\sqrt {2/n}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaimingInitializedWeightedMatrixOne = (torch.randn(xColumns, numberOfHiddenNodes) * math.sqrt(2/xColumns)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertNearZero(kaimingInitializedWeightedMatrixOne.mean())\n",
    "assertNearZero(kaimingInitializedWeightedMatrixOne.std() - 1 * math.sqrt(2/xColumns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Success!**\n",
    "Now we get to use the library method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraryKiamingWeightedMatrix = torch.zeros(xColumns, numberOfHiddenNodes).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "init.kaiming_normal_(libraryKiamingWeightedMatrix, mode='fan_out')\n",
    "assertNearZero(libraryKiamingWeightedMatrix.mean())\n",
    "assertNearZero(libraryKiamingWeightedMatrix.std() - 1 * math.sqrt(2/xColumns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "testMatrix = torch.zeros(xColumns, numberOfHiddenNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408 µs ± 733 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit init.kaiming_normal_(testMatrix, mode='fan_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425 µs ± 800 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit torch.randn(xColumns, numberOfHiddenNodes) * math.sqrt(2/xColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting closer to Ideal\n",
    "\n",
    "Apparently the Ideal state for our outputs ofter reLU transformation is to have a mean of zero\n",
    "    $$\\mu \\approx 0$$\n",
    "And a standard deviation of one\n",
    "    $$\\sigma \\approx 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "forwardPass = reLU(linearCombination(xValidationSetNormalized, \n",
    "                                     libraryKiamingWeightedMatrix, \n",
    "                                     biasVectorLayerOne))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6096, device='cuda:0'), tensor(0.8561, device='cuda:0'))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forwardPass.mean(), forwardPass.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f26943c8048>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter.scatter(x=range(numberOfHiddenNodes), y=forwardPass[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reLUEnhanced(vector): return vector.clamp_min(0.) - 0.5 # moves all the points above zero down to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhancedForwardPass = reLUEnhanced(linearCombination(xValidationSetNormalized, \n",
    "                                                     libraryKiamingWeightedMatrix, \n",
    "                                                     biasVectorLayerOne))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shifting closer to zero**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f2693f8c438>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter.scatter(x=range(numberOfHiddenNodes), y=enhancedForwardPass[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1096, device='cuda:0'), tensor(0.8561, device='cuda:0'))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhancedForwardPass.mean(), enhancedForwardPass.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalLibraryKiamingWeightedMatrix = torch.zeros(numberOfHiddenNodes, 1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dun\n"
     ]
    }
   ],
   "source": [
    "init.kaiming_normal_(finalLibraryKiamingWeightedMatrix, mode='fan_out')\n",
    "print('dun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Forward Pass CNN Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at what the input matrix's shape will be and then observe how the 2 weighted convolution matrices' shapes play into that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 784]), torch.Size([784, 50]), torch.Size([50, 1]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrainingSetNormalized.shape, libraryKiamingWeightedMatrix.shape, finalLibraryKiamingWeightedMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleModel(inputMatrix):\n",
    "    firstActivations = linearCombination(inputMatrix, \n",
    "                                         libraryKiamingWeightedMatrix, \n",
    "                                         biasVectorLayerOne)\n",
    "    clampedFirstActivations = reLUEnhanced(firstActivations)\n",
    "    lastActivations = linearCombination(clampedFirstActivations, \n",
    "                                        finalLibraryKiamingWeightedMatrix, \n",
    "                                        biasVectorLayerTwo)\n",
    "    return lastActivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 565 µs, sys: 0 ns, total: 565 µs\n",
      "Wall time: 373 µs\n"
     ]
    }
   ],
   "source": [
    "%time predictions = simpleModel(xTrainingSetNormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert predictions.shape == torch.Size([xTrainingSetNormalized.shape[0], 1]), \"{} does not equal {}\".format(predictions.shape, torch.Size([xTrainingSetNormalized.shape[0], 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready to learn!\n",
    "**Loss function**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def assertSameShape(actualVector, expectedVector):\n",
    "    assert actualVector.shape == expectedVector.shape, \"Input vectors do not have the same shape! {} and {}\".format(actualVector.shape, expectedVector.shape)\n",
    "def meanSquaredError(actualVector, expectedVector):\n",
    "    assertSameShape(actualVector, expectedVector)\n",
    "    return (actualVector - expectedVector).pow(2).mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 943 µs, sys: 0 ns, total: 943 µs\n",
      "Wall time: 748 µs\n"
     ]
    }
   ],
   "source": [
    "%time loss = meanSquaredError(predictions.squeeze(-1), yTrainingSet.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.5211, device='cuda:0')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal now is to minimize error, and we can do this by the process of backwards propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taking the deriviative (finding the gradient of the slope) of the loss function**\n",
    "\n",
    "*quick note*: `unsqueeze(-1)` will add a dimension to a vector eg `size([4])` -> `size([4, 1])` after unsqueezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanSquaredErrorGradient(actualVector, expectedVector):\n",
    "    squeezedActualVector = actualVector.squeeze(-1)\n",
    "    assertSameShape(squeezedActualVector, expectedVector)\n",
    "    lossVector = (squeezedActualVector - expectedVector)\n",
    "    actualVector.storedGradients = 2. * lossVector.unsqueeze(-1) / squeezedActualVector.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reLUErrorGradient(previousActivations, nextActivations):\n",
    "    previousActivations.storedGradients = (previousActivations > 0).float() * nextActivations.storedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearCombinationErrorGradient(inputMatrix, activationMatrix, weightedMatrix, biasVector):\n",
    "    inputMatrix.storedGradients = activationMatrix.storedGradients @ weightedMatrix.t() # t for transpose\n",
    "    weightedMatrixGradients = (inputMatrix.unsqueeze(-1) * activationMatrix.storedGradients.unsqueeze(-1)).sum(0)\n",
    "    weightedMatrix.storedGradients = weightedMatrixGradients\n",
    "    biasVector.storedGradients = activationMatrix.storedGradients.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def churnThenLearn(testInputs, validationOutputs):\n",
    "    #Churn\n",
    "    firstLayerActivations = linearCombination(testInputs, \n",
    "                                              libraryKiamingWeightedMatrix, \n",
    "                                              biasVectorLayerOne)\n",
    "    clampedFirstActivations = reLUEnhanced(firstLayerActivations)\n",
    "    finalLayerActivations = linearCombination(clampedFirstActivations, \n",
    "                                              finalLibraryKiamingWeightedMatrix, \n",
    "                                              biasVectorLayerTwo)\n",
    "    \n",
    "    loss = meanSquaredError(finalLayerActivations.squeeze(-1), validationOutputs)\n",
    "    print(\"Loss = {}\".format(loss))\n",
    "    \n",
    "    #Learn\n",
    "    meanSquaredErrorGradient(finalLayerActivations, validationOutputs)\n",
    "    linearCombinationErrorGradient(clampedFirstActivations, \n",
    "                                   finalLayerActivations, \n",
    "                                   finalLibraryKiamingWeightedMatrix,\n",
    "                                   biasVectorLayerTwo)\n",
    "    reLUErrorGradient(firstLayerActivations, finalLayerActivations)\n",
    "    linearCombinationErrorGradient(firstLayerActivations, \n",
    "                                   clampedFirstActivations, \n",
    "                                   libraryKiamingWeightedMatrix, \n",
    "                                   biasVectorLayerOne)\n",
    "    print(biasVectorLayerOne.storedGradients)\n",
    "    return firstLayerActivations, finalLayerActivations, biasVectorLayerOne, biasVectorLayerTwo, testInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraryKiamingWeightedMatrix.storedGradients,biasVectorLayerOne.storedGradients,finalLibraryKiamingWeightedMatrix.storedGradients,biasVectorLayerTwo.storedGradients = [None]*4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 17.521068572998047\n",
      "tensor([-6.1557], device='cuda:0')\n",
      "tensor([-0.1415,  0.1025, -0.8417,  0.5738,  0.9135, -0.1257, -1.2910, -1.6309,\n",
      "        -0.7278,  0.8069, -2.1002, -0.6503,  0.6072, -1.3273, -0.9282,  0.4091,\n",
      "        -0.8386, -0.5089,  2.4369, -0.1414,  0.8685, -0.4369,  3.6112,  0.7773,\n",
      "        -0.2282,  1.3746, -0.4636,  1.7433,  1.1299,  1.0155,  1.4915,  0.3330,\n",
      "        -1.6995, -1.5628, -0.5216, -0.7752,  1.5955, -1.7569, -0.3947, -1.0766,\n",
      "        -0.4512,  2.7352, -1.9251, -1.1356, -1.1130, -0.3359,  0.3295,  3.0265,\n",
      "        -2.4082, -0.4010], device='cuda:0')\n",
      "tensor([-0.1415,  0.1025, -0.8417,  0.5738,  0.9135, -0.1257, -1.2910, -1.6309,\n",
      "        -0.7278,  0.8069, -2.1002, -0.6503,  0.6072, -1.3273, -0.9282,  0.4091,\n",
      "        -0.8386, -0.5089,  2.4369, -0.1414,  0.8685, -0.4369,  3.6112,  0.7773,\n",
      "        -0.2282,  1.3746, -0.4636,  1.7433,  1.1299,  1.0155,  1.4915,  0.3330,\n",
      "        -1.6995, -1.5628, -0.5216, -0.7752,  1.5955, -1.7569, -0.3947, -1.0766,\n",
      "        -0.4512,  2.7352, -1.9251, -1.1356, -1.1130, -0.3359,  0.3295,  3.0265,\n",
      "        -2.4082, -0.4010], device='cuda:0')\n",
      "CPU times: user 22.8 ms, sys: 202 µs, total: 23 ms\n",
      "Wall time: 21.1 ms\n"
     ]
    }
   ],
   "source": [
    "%time firstLayerActivations, finalLayerActivations, biasVectorLayerOne, biasVectorLayerTwo, testInputs = churnThenLearn(xTrainingSetNormalized, yTrainingSet.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [50000 x 784], m2: [50000 x 50] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:266",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-e1aabaa12041>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# we don't actually need the loss in backward!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxt2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTrainingSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-151-e1aabaa12041>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(inp, targ)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# forward pass:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw12\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml2\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw22\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb22\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [50000 x 784], m2: [50000 x 50] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:266"
     ]
    }
   ],
   "source": [
    "w1g = firstLayerActivations.storedGradients.clone()\n",
    "w2g = finalLayerActivations.storedGradients.clone()\n",
    "b1g = biasVectorLayerOne.storedGradients.clone()\n",
    "b2g = biasVectorLayerTwo.storedGradients.clone()\n",
    "# ig  = testInputs.storedGradients.clone()\n",
    "xt2 = testInputs.clone().requires_grad_(True)\n",
    "w12 = firstLayerActivations.clone().requires_grad_(True)\n",
    "w22 = finalLayerActivations.clone().requires_grad_(True)\n",
    "b12 = biasVectorLayerOne.clone().requires_grad_(True)\n",
    "b22 = biasVectorLayerTwo.clone().requires_grad_(True)\n",
    "def forward(inp, targ):\n",
    "    # forward pass:\n",
    "    l1 = inp @ w12 + b12\n",
    "    l2 = relu(l1)\n",
    "    out = l2 @ w22 + b22\n",
    "    # we don't actually need the loss in backward!\n",
    "    return mse(out, targ)\n",
    "loss = forward(xt2, yTrainingSet)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
