{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_01 import *\n",
    "\n",
    "def getMnistData():\n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(lambda data: tensor(data), (x_train,y_train,x_valid,y_valid))\n",
    "\n",
    "def normalizeVector(vectorToNormalize, vectorMean, vectorStandardDeviation): \n",
    "    return (vectorToNormalize-vectorMean)/vectorStandardDeviation\n",
    "\n",
    "def assertNearZero(someScalar,tol=1e-3): assert someScalar.abs()<tol, f\"Near zero: {someScalar}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearCombination(vector, matrix, biasVector): return vector @ matrix + biasVector\n",
    "def reLU(vector): return vector.clamp_min(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Math Translation**\n",
    "\n",
    "- **x** is the values that we are given (in this case it is a bunch of vectors that repersent images of numbers)\n",
    "- **y** is the expected values that we want to predict (eg, is the image a \"1\" or \"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrainingSet, yTrainingSet, xValidationSet, yValidationSet = getMnistData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization\n",
    "\n",
    "Data needs to be [normalized](https://en.wikipedia.org/wiki/Normalization_(statistics)) so that it reduces the impact of outliers on the data set.\n",
    "\n",
    "One standard normaliziation is [standard score](https://en.wikipedia.org/wiki/Standard_score) which gives the data set a Gaussian Bell curve characteristic.\n",
    "\n",
    "**This is how we will normalize the image data**\n",
    "\n",
    "\n",
    "$$normalizedStandardScore ={value-mean  \\over standardDeviation }$$\n",
    "\n",
    "or in nerd words\n",
    "\n",
    "$$z ={x-\\mu \\over \\sigma}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrainingSetMean, xTrainingSetStandardDeviation = xTrainingSet.mean(), xTrainingSet.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1304), tensor(0.3073))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(xTrainingSetMean, xTrainingSetStandardDeviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time to normalize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrainingSetNormalized = normalizeVector(xTrainingSet, xTrainingSetMean, xTrainingSetStandardDeviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "xValidationSetNormalized = normalizeVector(xValidationSet, xValidationSet.mean(), xValidationSet.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data has been normalized, we would expect the mean of the normalized data to be somewhere around zero, like the bell curve would assume.\n",
    "\n",
    "![Bell Curve](./images/The_Normal_Distribution.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertNearZero(xTrainingSetNormalized.mean())\n",
    "assertNearZero(xValidationSetNormalized.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The standard deviation, or $\\sigma$ (sigma), of a **normalized distribution** should be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertNearZero(1 - xTrainingSetNormalized.std())\n",
    "assertNearZero(1 - xValidationSetNormalized.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Side Note**\n",
    "\n",
    "Just because the data is normalized, does not change the fact that the images remain intact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change default color to plasma\n",
    "plotter.rcParams['image.cmap'] = 'plasma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a1f2f8e80>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter.imshow(xTrainingSet[69].cpu().view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a1f2ab5f8>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter.imshow(xTrainingSetNormalized[69].cpu().view(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capture Data Set Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xRows, xColumns = xTrainingSetNormalized.shape\n",
    "inputChannels = yTrainingSet.max() + 1\n",
    "(xRows, xColumns, inputChannels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfHiddenNodes = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer Initialization\n",
    "\n",
    "Setting each layer in our convolutional network is important. Getting the right set of inital weights can lead to really good outputs. The following layer (done below) will have referenced the paper [Delving Deep into Rectifiers](https://arxiv.org/abs/1502.01852).\n",
    "\n",
    "Paper Dictonary\n",
    "---\n",
    "- $c$ - Number of Input Channels\n",
    "- $\\operatorname {Var} [\\vec{v}]$ - Variance of input vector, aka $\\sigma ^{2}$ (sigma squared), \n",
    "- $\\operatorname {E} [\\vec{v}]$ - Mean of itput vector, aka $\\mu$ (mu)\n",
    "- $b$ - Bias Vector\n",
    "- $n$ - Number of Columns\n",
    "\n",
    "##### Section 2.2 Synopsis\n",
    "Your weighted matrices should be initilaized such that the mean should be zero and the rest are symetrically dispresed around that mean (eg normalized)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple Initialization**\n",
    "\n",
    "Dividing the tensor by the number of total inputs of the each image brings the mean way down to zero. The distribution is also expected to have a standard deviation $\\sigma$ (sigma) of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightedLayerOne = (torch.randn(xColumns, numberOfHiddenNodes) / math.sqrt(xColumns))\n",
    "weightedLayerTwo = (torch.randn(numberOfHiddenNodes, 1) / math.sqrt(numberOfHiddenNodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertNearZero(weightedLayerOne.mean())\n",
    "assertNearZero(weightedLayerOne.std() - 1/math.sqrt(xColumns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We also initialize $b$ = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "biasVectorLayerOne = torch.zeros(numberOfHiddenNodes)\n",
    "biasVectorLayerTwo = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any linear combination of the initialized layers should have a $\\mu$=0 and $\\sigma$=1 because $y$ is just a linear combination of $\\vec{x}W + \\vec{b}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertNearZero(xValidationSetNormalized.mean())\n",
    "assertNearZero(1 - xValidationSetNormalized.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 784]), torch.Size([784, 50]))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xValidationSetNormalized.shape, weightedLayerOne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearWomboCombo = linearCombination(xValidationSetNormalized, weightedLayerOne, biasVectorLayerOne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaiming Note:**\n",
    "These should be close to zero because of our initializaitons, but this appears to not be the case.\n",
    "\n",
    "_The same goes for `reLU` processed vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0629), tensor(0.9759))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearWomboCombo.mean(), linearWomboCombo.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "reLUWomboCombo = reLU(linearCombination(xValidationSetNormalized, weightedLayerOne, biasVectorLayerOne))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3533), tensor(0.5589))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reLUWomboCombo.mean(), reLUWomboCombo.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paper Revelation**\n",
    "\n",
    "Apparently scaling the intialization matrix down by dividing it by it's standard deviation apparently helps a bunch.\n",
    "\n",
    ">This leads to a zero-mean Gaussian distribution whose standard deviation (std) is $\\sqrt {2/n}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaimingInitializedWeightedMatrixOne = (torch.randn(xColumns, numberOfHiddenNodes) * math.sqrt(2/xColumns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertNearZero(kaimingInitializedWeightedMatrixOne.mean())\n",
    "assertNearZero(kaimingInitializedWeightedMatrixOne.std() - 1 * math.sqrt(2/xColumns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Success!**\n",
    "Now we get to use the library method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraryKiamingWeightedMatrix = torch.zeros(xColumns, numberOfHiddenNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "init.kaiming_normal_(libraryKiamingWeightedMatrix, mode='fan_out')\n",
    "assertNearZero(libraryKiamingWeightedMatrix.mean())\n",
    "assertNearZero(libraryKiamingWeightedMatrix.std() - 1 * math.sqrt(2/xColumns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "testMatrix = torch.zeros(xColumns, numberOfHiddenNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263 µs ± 3.59 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit init.kaiming_normal_(testMatrix, mode='fan_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 µs ± 3.85 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit torch.randn(xColumns, numberOfHiddenNodes) * math.sqrt(2/xColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting closer to Ideal\n",
    "\n",
    "Apparently the Ideal state for our outputs ofter reLU transformation is to have a mean of zero\n",
    "    $$\\mu \\approx 0$$\n",
    "And a standard deviation of one\n",
    "    $$\\sigma \\approx 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "forwardPass = reLU(linearCombination(xValidationSetNormalized, \n",
    "                                     libraryKiamingWeightedMatrix, \n",
    "                                     biasVectorLayerOne))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5388), tensor(0.8203))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forwardPass.mean(), forwardPass.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a1f710710>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter.scatter(x=range(numberOfHiddenNodes), y=forwardPass[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reLUEnhanced(vector): return vector.clamp_min(0.) - 0.5 # moves all the points above zero down to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhancedForwardPass = reLUEnhanced(linearCombination(xValidationSetNormalized, \n",
    "                                                     libraryKiamingWeightedMatrix, \n",
    "                                                     biasVectorLayerOne))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shifting closer to zero**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a1f784e10>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter.scatter(x=range(numberOfHiddenNodes), y=enhancedForwardPass[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0388), tensor(0.8203))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhancedForwardPass.mean(), enhancedForwardPass.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalLibraryKiamingWeightedMatrix = torch.zeros(numberOfHiddenNodes, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dun\n"
     ]
    }
   ],
   "source": [
    "init.kaiming_normal_(finalLibraryKiamingWeightedMatrix, mode='fan_out')\n",
    "print('dun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Forward Pass CNN Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at what the input matrix's shape will be and then observe how the 2 weighted convolution matrices' shapes play into that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 784]), torch.Size([784, 50]), torch.Size([50, 1]))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrainingSetNormalized.shape, libraryKiamingWeightedMatrix.shape, finalLibraryKiamingWeightedMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleModel(inputMatrix):\n",
    "    firstActivations = linearCombination(inputMatrix, \n",
    "                                         libraryKiamingWeightedMatrix, \n",
    "                                         biasVectorLayerOne)\n",
    "    clampedFirstActivations = reLUEnhanced(firstActivations)\n",
    "    lastActivations = linearCombination(clampedFirstActivations, \n",
    "                                        finalLibraryKiamingWeightedMatrix, \n",
    "                                        biasVectorLayerTwo)\n",
    "    return lastActivations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 183 ms, sys: 53.7 ms, total: 236 ms\n",
      "Wall time: 69.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time predictions = simpleModel(xTrainingSetNormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert predictions.shape == torch.Size([xTrainingSetNormalized.shape[0], 1]), \"{} does not equal {}\".format(predictions.shape, torch.Size([xTrainingSetNormalized.shape[0], 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready to learn!\n",
    "**Loss function**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def assertSameShape(actualVector, expectedVector):\n",
    "    assert actualVector.shape == expectedVector.shape, \"Input vectors do not have the same shape! {} and {}\".format(actualVector.shape, expectedVector.shape)\n",
    "def meanSquaredError(actualVector, expectedVector):\n",
    "    assertSameShape(actualVector, expectedVector)\n",
    "    return (actualVector - expectedVector).pow(2).mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.47 ms, sys: 1.96 ms, total: 3.44 ms\n",
      "Wall time: 1.06 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = meanSquaredError(predictions.squeeze(-1), yTrainingSet.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(31.7647)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal now is to minimize error, and we can do this by the process of backwards propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taking the deriviative (finding the gradient of the slope) of the loss function**\n",
    "\n",
    "*quick note*: `unsqueeze(-1)` will add a dimension to a vector eg `size([4])` -> `size([4, 1])` after unsqueezing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Gradient\n",
    "This case, the cost is the mean squared error\n",
    "So we want the gradient of the $\\vec{C} = \\vec{y} - \\hat{y}$\n",
    "\n",
    "For this example, the expected vector is **the digits the image data represents** (so 50000 digits) and the output vector is the predicted digit (for the 50000 of inputs).\n",
    "\n",
    "$\\vec{y} = validation vector$ (What digit the picture is)\n",
    "\n",
    "$\\vec{x} = input vector$ (Vector of images)\n",
    "\n",
    "$\\vec{w} = weighted vector$ (prediction layer)\n",
    "\n",
    "$\\hat{y} = \\vec{x}\\vec{w}$ (Digit predictions)\n",
    "\n",
    "$\\vec{C} = (\\vec{y} - \\hat{y})^2$ (Cost = mean squared error)\n",
    "\n",
    "$\\partial \\vec{c} \\over \\partial \\vec{w}$ $= 2(\\vec{y} - \\hat{y})$\n",
    "\n",
    "---\n",
    "\n",
    "$U_1(\\vec{x}, \\vec{w}) = \\vec{x}\\vec{w}$\n",
    "\n",
    "$U_2(\\vec{y}, U_1) = 2(\\vec{y} - U_1)$\n",
    "\n",
    "$C(U_2) = U_2^2$\n",
    "\n",
    "$\\partial \\vec{c} \\over \\partial \\vec{w}$ $= 2U_2$\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "$\\hat{y}$ is going to be a vector that we predicted as the expected output\n",
    "\n",
    "$cost = C$\n",
    "\n",
    "\n",
    "**Things to keep in mind**\n",
    "\n",
    "The gradient is calculated, only then can it be multiplied by the learning rate and then subtracted, so that it can move the weights of each activation layer in the right direction (lower loss).\n",
    "\n",
    "So the following only calculates the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanSquaredErrorGradient(actualVector, expectedVector):\n",
    "    squeezedActualVector = actualVector.squeeze()\n",
    "    assertSameShape(squeezedActualVector, expectedVector)\n",
    "    yHat = (squeezedActualVector - expectedVector)\n",
    "    actualVector.storedGradients = 2. * yHat.unsqueeze(-1) / actualVector.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ReLU Gradient calculation**\n",
    "We are going to take the gradients calculated from the gradients of the layer that comes after ReLU was called, and only take the gradients whose components have a greater than zero activation from the previous activation layer (the one called before it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reLUErrorGradient(previousActivations, nextActivations):\n",
    "    previousActivations.storedGradients = (previousActivations > 0).float() * nextActivations.storedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearCombinationErrorGradient(inputMatrix, activationMatrix, weightedMatrix, biasVector):\n",
    "    inputMatrix.storedGradients = activationMatrix.storedGradients @ weightedMatrix.t() # t for transpose\n",
    "    \n",
    "    # Reduce the gradients from all of the images\n",
    "    weightedMatrixGradients = (inputMatrix.unsqueeze(-1) * activationMatrix.storedGradients.unsqueeze(1)).sum(0)\n",
    "    weightedMatrix.storedGradients = weightedMatrixGradients\n",
    "    biasVector.storedGradients = activationMatrix.storedGradients.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def churnThenLearn(testInputs, validationOutputs):\n",
    "    #Churn\n",
    "    firstLayerActivations = linearCombination(testInputs, \n",
    "                                              libraryKiamingWeightedMatrix, \n",
    "                                              biasVectorLayerOne)\n",
    "    clampedFirstActivations = reLUEnhanced(firstLayerActivations)\n",
    "    predictions = linearCombination(clampedFirstActivations, \n",
    "                                              finalLibraryKiamingWeightedMatrix, \n",
    "                                              biasVectorLayerTwo)\n",
    "    \n",
    "    loss = meanSquaredError(predictions.squeeze(-1), validationOutputs)\n",
    "    print(\"Loss = {}\".format(loss))\n",
    "    \n",
    "    #Learn\n",
    "    meanSquaredErrorGradient(predictions, validationOutputs)\n",
    "    linearCombinationErrorGradient(clampedFirstActivations, \n",
    "                                   predictions, \n",
    "\n",
    "                                   finalLibraryKiamingWeightedMatrix,\n",
    "                                   biasVectorLayerTwo)\n",
    "    reLUErrorGradient(firstLayerActivations, clampedFirstActivations)\n",
    "    linearCombinationErrorGradient(testInputs, \n",
    "                                   firstLayerActivations, \n",
    "                                   libraryKiamingWeightedMatrix, \n",
    "                                   biasVectorLayerOne)\n",
    "    return firstLayerActivations, predictions, biasVectorLayerOne, biasVectorLayerTwo, testInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraryKiamingWeightedMatrix.storedGradients,biasVectorLayerOne.storedGradients,finalLibraryKiamingWeightedMatrix.storedGradients,biasVectorLayerTwo.storedGradients = [None]*4 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 31.764667510986328\n",
      "(torch.Size([50000, 50]), torch.Size([50000, 1]))\n",
      "(torch.Size([50000, 784]), torch.Size([50000, 50]))\n",
      "CPU times: user 11.1 s, sys: 24.8 s, total: 35.9 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%time firstLayerActivations, finalLayerActivations, biasVectorLayerOne, biasVectorLayerTwo, testInputs = churnThenLearn(xTrainingSetNormalized, yTrainingSet.float())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1g = libraryKiamingWeightedMatrix.storedGradients.clone()\n",
    "w2g = finalLibraryKiamingWeightedMatrix.storedGradients.clone()\n",
    "b1g = biasVectorLayerOne.storedGradients.clone()\n",
    "b2g = biasVectorLayerTwo.storedGradients.clone()\n",
    "ig  = testInputs.storedGradients.clone()\n",
    "xt2 = xTrainingSetNormalized.clone().requires_grad_(True)\n",
    "w12 = libraryKiamingWeightedMatrix.clone().requires_grad_(True)\n",
    "w22 = finalLibraryKiamingWeightedMatrix.clone().requires_grad_(True)\n",
    "b12 = biasVectorLayerOne.clone().requires_grad_(True)\n",
    "b22 = biasVectorLayerTwo.clone().requires_grad_(True)\n",
    "def forward(inp, targ):\n",
    "    # forward pass:\n",
    "    l1 = inp @ w12 + b12\n",
    "    l2 = reLUEnhanced(l1)\n",
    "    out = l2 @ w22 + b22\n",
    "    # we don't actually need the loss in backward!\n",
    "    return meanSquaredError(out.squeeze(-1), targ)\n",
    "loss = forward(xt2, yTrainingSet.float())\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNear(w22.grad, w2g)\n",
    "testNear(b22.grad, b2g)\n",
    "testNear(w12.grad, w1g)\n",
    "testNear(b12.grad, b1g)\n",
    "testNear(xt2.grad, ig )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __call__(self, activationMatrix):\n",
    "        self.activationMatrix = activationMatrix\n",
    "        self.activations = activationMatrix.clamp_(0.) - 0.5\n",
    "        return self.activations\n",
    "    \n",
    "    def backwardsPropagation(self):\n",
    "        self.activationMatrix.storedGradients = (self.activationMatrix > 0).float() * self.activations.storedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearCombo():\n",
    "    def __init__(self, weightedMatrix, biasVector):\n",
    "        self.weightedMatrix = weightedMatrix\n",
    "        self.biasVector = biasVector\n",
    "        \n",
    "    def __call__(self, inputVector):\n",
    "        self.inputVector = inputVector\n",
    "        self.activationMatrix = self.inputVector @ self.weightedMatrix + self.biasVector\n",
    "        return self.activationMatrix\n",
    "    \n",
    "    def backwardsPropagation(self):\n",
    "        self.inputVector.storedGradients = self.activationMatrix.storedGradients @ self.weightedMatrix.t()\n",
    "        weightedMatrixGradients = (self.inputVector.unsqueeze(-1) * self.activationMatrix.storedGradients.unsqueeze(1)).sum(0)\n",
    "        self.weightedMatrix.storedGradients = weightedMatrixGradients\n",
    "        self.biasVector.storedGradients = self.activationMatrix.storedGradients.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanSquaredError():\n",
    "    def __call__(self, predictedVector, expectedVector):\n",
    "        self.predictedVector = predictedVector\n",
    "        self.expectedVector = expectedVector\n",
    "        self.meanSquaredError = (self.predictedVector - self.expectedVector).pow(2).mean()\n",
    "        return self.meanSquaredError\n",
    "    \n",
    "    def backwardsPropagation(self):\n",
    "        squeezedActualVector = self.predictedVector.squeeze()\n",
    "        assertSameShape(squeezedActualVector, self.expectedVector)\n",
    "        yHat = (squeezedActualVector - self.expectedVector)\n",
    "        self.predictedVector.storedGradients = 2. * yHat.unsqueeze(-1) / self.predictedVector.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel():\n",
    "    def __init__(self, weightedLayerOne, weightedLayerTwo, biasVectorOne, biasVectorTwo):\n",
    "        self.convolutionLayers = [LinearCombo(weightedLayerOne, biasVectorOne), ReLU(), LinearCombo(weightedLayerTwo, biasVectorTwo)]\n",
    "        self.cost = MeanSquaredError()\n",
    "    def __call__(self, normalizedInputs, expectedOutputs):\n",
    "        activations = normalizedInputs\n",
    "        for layer in self.convolutionLayers: activations = layer(activations)\n",
    "        return self.cost(activations, expectedOutputs)\n",
    "        \n",
    "    def backwardsPropagation(self):\n",
    "        self.cost.backwardsPropagation()\n",
    "        for layer in reversed(self.convolutionLayers): layer.backwardsPropagation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraryKiamingWeightedMatrix.storedGradients,biasVectorLayerOne.storedGradients,finalLibraryKiamingWeightedMatrix.storedGradients,biasVectorLayerTwo.storedGradients = [None]*4 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomModel(libraryKiamingWeightedMatrix, finalLibraryKiamingWeightedMatrix, biasVectorLayerOne, biasVectorLayerTwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30.9812)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xTrainingSetNormalized, yTrainingSet.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.backwardsPropagation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dun\n"
     ]
    }
   ],
   "source": [
    "model.convolutionLayers[2].weightedMatrix.storedGradients\n",
    "print('dun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "customeModelWeightedLayer2Gradients = model.convolutionLayers[2].weightedMatrix.storedGradients\n",
    "customeModelBiasLayer2Gradients = model.convolutionLayers[2].biasVector.storedGradients\n",
    "customeModelWeightedLayer1Gradients = model.convolutionLayers[0].weightedMatrix.storedGradients\n",
    "customeModelBiasLayer1Gradients = model.convolutionLayers[0].biasVector.storedGradients\n",
    "customeModelInputGradients = model.convolutionLayers[0].inputVector.storedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNear(w22.grad, customeModelWeightedLayer2Gradients)\n",
    "testNear(b22.grad, customeModelBiasLayer2Gradients)\n",
    "testNear(w12.grad, customeModelWeightedLayer1Gradients)\n",
    "testNear(b12.grad, customeModelBiasLayer1Gradients)\n",
    "testNear(xt2.grad, customeModelInputGradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearComboEnhanced():\n",
    "    def __init__(self, weightedMatrix, biasVector):\n",
    "        self.weightedMatrix = weightedMatrix\n",
    "        self.biasVector = biasVector\n",
    "        \n",
    "    def __call__(self, inputVector):\n",
    "        self.inputVector = inputVector\n",
    "        self.activationMsatrix = self.inputVector @ self.weightedMatrix + self.biasVector\n",
    "        return self.activationMatrix\n",
    "    \n",
    "    def backwardsPropagation(self):\n",
    "        self.inputVector.storedGradients = self.activationMatrix.storedGradients @ self.weightedMatrix.t()\n",
    "        self.weightedMatrix.storedGradients = torch.einsum('ij,jk->ik', self.inputVector, self.activationMatrix.storedGradients)\n",
    "        self.biasVector.storedGradients = self.activationMatrix.storedGradients.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModelEnhanced():\n",
    "    def __init__(self, weightedLayerOne, weightedLayerTwo, biasVectorOne, biasVectorTwo):\n",
    "        self.convolutionLayers = [LinearCombo(weightedLayerOne, biasVectorOne), ReLU(), LinearCombo(weightedLayerTwo, biasVectorTwo)]\n",
    "        self.cost = MeanSquaredError()\n",
    "    def __call__(self, normalizedInputs, expectedOutputs):\n",
    "        activations = normalizedInputs\n",
    "        for layer in self.convolutionLayers: activations = layer(activations)\n",
    "        return self.cost(activations, expectedOutputs)\n",
    "        \n",
    "    def backwardsPropagation(self):\n",
    "        self.cost.backwardsPropagation()\n",
    "        for layer in reversed(self.convolutionLayers): layer.backwardsPropagation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraryKiamingWeightedMatrix.storedGradients,biasVectorLayerOne.storedGradients,finalLibraryKiamingWeightedMatrix.storedGradients,biasVectorLayerTwo.storedGradients = [None]*4 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhancedModel = CustomModelEnhanced(libraryKiamingWeightedMatrix, finalLibraryKiamingWeightedMatrix, biasVectorLayerOne, biasVectorLayerTwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30.9812)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhancedModel(xTrainingSetNormalized, yTrainingSet.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhancedModel.backwardsPropagation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "customEnhancedModelWeightedLayer2Gradients = enhancedModel.convolutionLayers[2].weightedMatrix.storedGradients\n",
    "customEnhancedModelBiasLayer2Gradients = enhancedModel.convolutionLayers[2].biasVector.storedGradients\n",
    "customEnhancedModelWeightedLayer1Gradients = enhancedModel.convolutionLayers[0].weightedMatrix.storedGradients\n",
    "customEnhancedModelBiasLayer1Gradients = enhancedModel.convolutionLayers[0].biasVector.storedGradients\n",
    "customEnhancedModelInputGradients = enhancedModel.convolutionLayers[0].inputVector.storedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNear(w22.grad, customEnhancedModelWeightedLayer2Gradients)\n",
    "testNear(b22.grad, customEnhancedModelBiasLayer2Gradients)\n",
    "testNear(w12.grad, customEnhancedModelWeightedLayer1Gradients)\n",
    "testNear(b12.grad, customEnhancedModelBiasLayer1Gradients)\n",
    "testNear(xt2.grad, customEnhancedModelInputGradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 02_CNN_From_Scratch.ipynb to exp/nb_02.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py 02_CNN_From_Scratch.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
