
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nb/03_MINI_BATCH_FROM_SCRATCH.ipynb

from exp.nb_02 import *
import torch.nn.functional as Functional

def accuracy(predictionVector, expectedVector):
    return (torch.argmax(predictionVector, dim=1) == expectedVector).float().mean()

from torch import optim

class SelfLearningLibraryModel(torch.nn.Module):
    def __init__(self, inputSize, numberHiddenLayers, classes, learningRate):
        super().__init__()
        self.layers = torch.nn.Sequential(
            torch.nn.Linear(inputSize, numberHiddenLayers),
            torch.nn.ReLU(),
            torch.nn.Linear(numberHiddenLayers, classes)
        )
        self.optimizer = optim.SGD(self.parameters(), learningRate)

    def __call__(self, inputMatrix): return self.layers(inputMatrix)

    def learn(self):
        self.optimizer.step()
        self.optimizer.zero_grad()

class Dataset:
    def __init__(self, xVector, yVector):
        self.xVector = xVector
        self.yVector = yVector
    def __len__(self): return len(self.xVector)
    def __getitem__(self, i): return self.xVector[i],self.yVector[i]

def collateTuple(tupl):
    xColumn, yColumn = zip(*tupl)
    return torch.stack(xColumn), torch.stack(yColumn)

from torch.utils.data import DataLoader, SequentialSampler, RandomSampler

def createDataLoaders(trainingDataSet, validationDataSet, batchSize, **kwargs):
    return (
        DataLoader(trainingDataSet, batch_size=batchSize, shuffle=True, **kwargs),
        DataLoader(validationDataSet, batch_size=batchSize*2, **kwargs)
    )