{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_06 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-7.6999e-06),\n",
       " <function Tensor.std>,\n",
       " tensor(-7.0751e-08),\n",
       " tensor(1.0000))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTraining, yTraining, xValidation, yValidation = getMnistData()\n",
    "xTrainingNormalized, xValidationNormalized = normalizeVectors(xTraining, xValidation)\n",
    "(xTrainingNormalized.mean(), xTrainingNormalized.std, xValidationNormalized.mean(), xValidationNormalized.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfClasses = 10\n",
    "hiddenLayerOutput = 50\n",
    "batchSize = 64\n",
    "lossFuction = Functional.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDataSet, validationDataSet = Dataset(xTrainingNormalized, yTraining), Dataset(xValidationNormalized, yValidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDataLoader, validationDataLoader = createDataLoaders(trainingDataSet, validationDataSet, batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageDataBunch = DataBunch(trainingDataLoader, validationDataLoader, numberOfClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layerSizes = [8, 16, 32, 64, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): LambdaLayer()\n",
       "  (1): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (1): GeneralRectifiedLinearUnit()\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): GeneralRectifiedLinearUnit()\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): GeneralRectifiedLinearUnit()\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): GeneralRectifiedLinearUnit()\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): GeneralRectifiedLinearUnit()\n",
       "  )\n",
       "  (6): AdaptiveAvgPool2d(output_size=1)\n",
       "  (7): LambdaLayer()\n",
       "  (8): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolutionalModelSR1 = createBetterConvolutionModel(numberOfClasses, layerSizes)\n",
    "convolutionalModelSR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0994)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(convolutionalModelSR1(xTraining), yTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = [0.3, 0.7]\n",
    "weightsScheduler = aggregateSchedulers(phases, createCosineSchedulers(0.3, 0.6, 0.2)) \n",
    "biasScheduler = aggregateSchedulers(phases, createCosineSchedulers(0.9, 1.8, 0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = TeacherWithHooks(schedulingFunctions=[weightsScheduler, biasScheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 Training: Loss 0.4548206627368927 Accuracy 0.8388347029685974\n",
      "Epoch #0 Validation: Loss 0.08740277588367462 Accuracy 0.9732001423835754\n",
      "\n",
      "Epoch #1 Training: Loss 0.1314106285572052 Accuracy 0.9611372947692871\n",
      "Epoch #1 Validation: Loss 0.14704951643943787 Accuracy 0.9635087251663208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teacher.teachModel(convolutionalModelSR1, imageDataBunch, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
